@article{albahnassiRealTimeMotionPlanning2012,
  title = {Near {{Real-Time Motion Planning}} and {{Simulation}} of {{Cranes}} in {{Construction}}: {{Framework}} and {{System Architecture}}},
  shorttitle = {Near {{Real-Time Motion Planning}} and {{Simulation}} of {{Cranes}} in {{Construction}}},
  author = {AlBahnassi, Homam and Hammad, Amin},
  date = {2012-01-01},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {26},
  number = {1},
  pages = {54--63},
  publisher = {American Society of Civil Engineers},
  issn = {1943-5487},
  doi = {10.1061/(ASCE)CP.1943-5487.0000123},
  abstract = {Motion planning of cranes is an important issue in construction projects, where rapid and accurate planning directly affects the safety and productivity of operations. The work presented in this paper is directed toward developing a framework for near ...},
  langid = {english},
  keywords = {Construction management,Construction safety,Cranes,Framework,Motion,Motion planning,Productivity,Safety,Simulation},
  file = {E:\tjustu\研究生\Zotero\storage\JA9YW8X9\AlBahnassi和Hammad - 2012 - Near Real-Time Motion Planning and Simulation of Cranes in Construction Framework and System Archit.pdf}
}

@article{alonsoMiniNetEfficientSemantic2020,
  title = {{{MiniNet}}: {{An Efficient Semantic Segmentation ConvNet}} for {{Real-Time Robotic Applications}}},
  shorttitle = {{{MiniNet}}},
  author = {Alonso, Iñigo and Riazuelo, Luis and Murillo, Ana C.},
  date = {2020-08},
  journaltitle = {IEEE Transactions on Robotics},
  volume = {36},
  number = {4},
  pages = {1340--1347},
  issn = {1941-0468},
  doi = {10.1109/TRO.2020.2974099},
  abstract = {Efficient models for semantic segmentation, in terms of memory, speed, and computation, could boost many robotic applications with strong computational and temporal restrictions. This article presents a detailed analysis of different techniques for efficient semantic segmentation. Following this analysis, we have developed a novel architecture, MiniNet-v2, an enhanced version of MiniNet. MiniNet-v2 is built considering the best option depending on CPU or GPU availability. It reaches comparable accuracy to the state-of-the-art models but uses less memory and computational resources. We validate and analyze the details of our architecture through a comprehensive set of experiments on public benchmarks (Cityscapes, Camvid, and COCO-Text datasets), showing its benefits over relevant prior work. Our experiments include a sample application where these models can boost existing robotic applications.},
  keywords = {Computational modeling,Computer architecture,Convolution,Deep learning,efficient models,Kernel,Robots,scene understanding,semantic segmentation,Semantics,Standards},
  file = {E:\tjustu\研究生\Zotero\storage\QXBX8ZVK\Alonso 等 - 2020 - MiniNet An Efficient Semantic Segmentation ConvNet for Real-Time Robotic Applications.pdf}
}

@article{caltagironeLIDARCameraFusion2019,
  title = {{{LIDAR}}–Camera Fusion for Road Detection Using Fully Convolutional Neural Networks},
  author = {Caltagirone, Luca and Bellone, Mauro and Svensson, Lennart and Wahde, Mattias},
  date = {2019-01-01},
  journaltitle = {Robotics and Autonomous Systems},
  shortjournal = {Robotics and Autonomous Systems},
  volume = {111},
  pages = {125--131},
  issn = {0921-8890},
  doi = {10.1016/j.robot.2018.11.002},
  abstract = {In this work, a deep learning approach has been developed to carry out road detection by fusing LIDAR point clouds and camera images. An unstructured and sparse point cloud is first projected onto the camera image plane and then upsampled to obtain a set of dense 2D images encoding spatial information. Several fully convolutional neural networks (FCNs) are then trained to carry out road detection, either by using data from a single sensor, or by using three fusion strategies: early, late, and the newly proposed cross fusion. Whereas in the former two fusion approaches, the integration of multimodal information is carried out at a predefined depth level, the cross fusion FCN is designed to directly learn from data where to integrate information; this is accomplished by using trainable cross connections between the LIDAR and the camera processing branches. To further highlight the benefits of using a multimodal system for road detection, a data set consisting of visually challenging scenes was extracted from driving sequences of the KITTI raw data set. It was then demonstrated that, as expected, a purely camera-based FCN severely underperforms on this data set. A multimodal system, on the other hand, is still able to provide high accuracy. Finally, the proposed cross fusion FCN was evaluated on the KITTI road benchmark where it achieved excellent performance, with a MaxF score of 96.03\%, ranking it among the top-performing approaches.},
  keywords = {Deep learning,Intelligent vehicles,Road detection,Sensor fusion},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\WDWSBAYG\\Caltagirone 等 - 2019 - LIDAR–camera fusion for road detection using fully convolutional neural networks.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\WT4Y3C84\\S0921889018300496.html}
}

@article{chaeApplicationRFIDTechnology2010,
  title = {Application of {{RFID}} Technology to Prevention of Collision Accident with Heavy Equipment},
  author = {Chae, Soungho and Yoshida, Tomohiro},
  date = {2010-05-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  series = {25th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  volume = {19},
  number = {3},
  pages = {368--374},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2009.12.008},
  abstract = {This paper describes the application of RFID (Radio Frequency Identification) technology to prevention of collision accidents with heavy equipment such as hydraulic excavators and cranes. Past disasters involving heavy equipment are evaluated to clarify the causes of accidents, and the functions of support systems for preventing collisions are defined. A system design is proposed with a working area obtained using RFID technology that is given a role from defined functions. A prototype has been developed using an active type RFID tag for the functions of a support system. RFID tag data were obtained from an actual construction site, and it is clarified that the prototype is applicable to estimation of working areas for the prevention of collision accidents.},
  keywords = {Collision accident,Past disasters,RFID,Safety management,Working area},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\6R4PAJWI\\Chae和Yoshida - 2010 - Application of RFID technology to prevention of collision accident with heavy equipment.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\CHDB8Q2F\\S0926580509001976.html}
}

@article{chiPhysicsbasedSimulationApproach2010,
  title = {A Physics-Based Simulation Approach for Cooperative Erection Activities},
  author = {Chi, Hung-Lin and Kang, Shih-Chung},
  date = {2010-10-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {19},
  number = {6},
  pages = {750--761},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2010.03.004},
  abstract = {Cooperative erection activities are critical to projects which involve the erection of heavy loads or the installation of special equipment. Detailed simulation on computer prior to construction can identify constructability problems, and subsequently avoided during actual erections. This paper describes an integrated approach for simulating the detailed motions of cranes. This research develops a physics-based model that follows the principle of closed-form forward kinematics and constraint-based dynamics to present the dual-crane mechanism mathematically — a non-trivial task. This model can be used to analyze the inputs from the users (i.e. virtual crane operators) and simultaneously compute the cables sway and reaction of collisions. We also implemented the model on computer and developed a simulation system, Erection Director, to render realistic cooperative erection activities. A demonstration of simulating two-crane lift has been built and three performance tests including a small building (840 elements), a medium building (1937 elements) and a large building (2682 elements) validate the feasibility of the proposed approach. The test results indicate that Erection Director can support real-time and physics-based visualization of cooperative erections.},
  keywords = {Construction crane,Cooperative erection activities,Erection planning,Forward kinematics,Physics-based simulation,Rigid body dynamics,Robotics,Virtual reality},
  file = {E:\tjustu\研究生\Zotero\storage\BIILMAR6\S0926580510000488.html}
}

@article{desilvaRobustFusionLiDAR2018,
  title = {Robust {{Fusion}} of {{LiDAR}} and {{Wide-Angle Camera Data}} for {{Autonomous Mobile Robots}}},
  author = {De Silva, Varuna and Roche, Jamie and Kondoz, Ahmet},
  date = {2018-08},
  journaltitle = {Sensors},
  volume = {18},
  number = {8},
  pages = {2730},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s18082730},
  abstract = {Autonomous robots that assist humans in day to day living tasks are becoming increasingly popular. Autonomous mobile robots operate by sensing and perceiving their surrounding environment to make accurate driving decisions. A combination of several different sensors such as LiDAR, radar, ultrasound sensors and cameras are utilized to sense the surrounding environment of autonomous vehicles. These heterogeneous sensors simultaneously capture various physical attributes of the environment. Such multimodality and redundancy of sensing need to be positively utilized for reliable and consistent perception of the environment through sensor data fusion. However, these multimodal sensor data streams are different from each other in many ways, such as temporal and spatial resolution, data format, and geometric alignment. For the subsequent perception algorithms to utilize the diversity offered by multimodal sensing, the data streams need to be spatially, geometrically and temporally aligned with each other. In this paper, we address the problem of fusing the outputs of a Light Detection and Ranging (LiDAR) scanner and a wide-angle monocular image sensor for free space detection. The outputs of LiDAR scanner and the image sensor are of different spatial resolutions and need to be aligned with each other. A geometrical model is used to spatially align the two sensor outputs, followed by a Gaussian Process (GP) regression-based resolution matching algorithm to interpolate the missing data with quantifiable uncertainty. The results indicate that the proposed sensor data fusion framework significantly aids the subsequent perception steps, as illustrated by the performance improvement of a uncertainty aware free space detection algorithm.},
  langid = {english},
  keywords = {assistive robots,autonomous vehicles,depth sensing,free space detection,Gaussian Process regression,LiDAR,sensor data fusion},
  file = {E:\tjustu\研究生\Zotero\storage\L2KSHFF7\De Silva 等 - 2018 - Robust Fusion of LiDAR and Wide-Angle Camera Data for Autonomous Mobile Robots.pdf}
}

@article{duttaAutomaticReplanningLifting2020,
  title = {Automatic Re-Planning of Lifting Paths for Robotized Tower Cranes in Dynamic {{BIM}} Environments},
  author = {Dutta, Souravik and Cai, Yiyu and Huang, Lihui and Zheng, Jianmin},
  date = {2020-02-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {110},
  pages = {102998},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2019.102998},
  abstract = {Computer-Aided Lift Planning (CALP) systems provide smart and optimal solutions for automatic crane lifting, supported by intelligent decision-making and planning algorithms along with computer graphics and simulations. Re-planning collision-free optimal lifting paths in near real-time is an essential feature for a robotized crane operating in a construction environment that is changing with time. The primary focus of the present research work is to develop a re-planning module for the CALP system designed at Nanyang Technological University. The CALP system employs GPU-based parallelization approach for discrete and continuous collision detection as well as for path planning. Building Information Modeling (BIM) is utilized in the system, and a Single-level Depth Map (SDM) representation is implemented to reduce the huge data set of BIM models for usage in discrete and continuous collision detection. The proposed re-planning module constitutes of a Decision Support System (DSS) and a Path Re-planner (PRP). A novel re-planning decision making algorithm using multi-level Oriented Bounding Boxes (OBBs) is formulated for the DSS. A path re-planning strategy via updating the start configuration for the local path is devised for the PRP. Two case studies are carried out with real-world models of a building and a specific tower crane to validate the effective performance of the re-planning module. The results show excellent decision accuracy and near real-time re-planning with high optimality.},
  keywords = {Building Information Modeling (BIM),Crane lifting path re-planning,Dynamic obstacles,Multi-level oriented bounding boxes,Robotized tower cranes,Single-level depth map},
  file = {E:\tjustu\研究生\Zotero\storage\RVJS5T38\S0926580519308684.html}
}

@article{fangAssessmentOperatorsSituation2018,
  title = {Assessment of Operator's Situation Awareness for Smart Operation of Mobile Cranes},
  author = {Fang, Yihai and Cho, Yong K. and Durso, Frank and Seo, Jongwon},
  date = {2018-01-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {85},
  pages = {65--75},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2017.10.007},
  abstract = {Equipment operators play an integral role in the safe and efficient operation of heavy equipment. They observe the environment, understand the situation, and make decisions and actions accordingly. Compared with other types of equipment, operating a crane is more sophisticated and mentally demanding, and thus crane operators are more vulnerable to human errors. Therefore, special considerations to mitigate operator errors should be taken when designing an operator-assistance system for construction cranes. With the goal of improving the operators' situation awareness (SA) of safety risks, this research presents a novel framework and practical system architecture for an operator-assistance system by leveraging real-time motion sensing and 3D modeling of dynamic workspaces. An approach for evaluating operators' SA was proposed to validate the effectiveness of the assistance system in actual lifting operations. Results in a series of field tests indicated that the prototype system improved the operators' SA which resulted in an improved lift performance.},
  keywords = {Crane operator,Lift performance,Real-time lift assistance,Situation awareness,Workload},
  file = {E:\tjustu\研究生\Zotero\storage\W5KJQEWN\S0926580517303473.html}
}

@article{fangFrameworkRealtimeProactive2016,
  title = {A Framework for Real-Time pro-Active Safety Assistance for Mobile Crane Lifting Operations},
  author = {Fang, Yihai and Cho, Yong K. and Chen, Jingdao},
  date = {2016-12-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {72},
  pages = {367--379},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2016.08.025},
  abstract = {Despite many safety considerations addressed in lift pre-planning, the ability to provide real-time safety assistance to crane operators and to mitigate human errors during the lifting operation is missing. This research developed a framework for real-time pro-active safety assistance for mobile crane lifting operations. First, crane poses are reconstructed in real-time based on the critical motions of crane parts captured by a sensor system. Second, as-is lift site conditions are automatically modeled and updated based on point cloud data. Lastly, the risk of colliding the crane parts and lifted load into nearby obstructions is pro-actively analyzed and warnings are provided to the operator through a graphical user interface. A prototype system was developed based on the framework and deployed on a mobile crane. Field test results indicate that the system can accurately reconstruct crane motion in real-time and provide pro-active warnings that allow the operator to make timely decisions to mitigate the risk.},
  keywords = {3D reconstruction,Collision hazard analysis,Crane motion capturing,Crane safety,Human error,Point cloud,Real-time},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\XU5WMUY8\\Fang 等 - 2016 - A framework for real-time pro-active safety assistance for mobile crane lifting operations.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\AQV4A4KH\\S0926580516301807.html}
}

@article{fangVisionbasedLoadSway2018a,
  title = {Vision-Based Load Sway Monitoring to Improve Crane Safety in Blind Lifts},
  author = {Fang, Yihai and Chen, Jingdao and Cho, Yong K. and Kim, Kinam and Zhang, Sijie and Perez, Esau},
  date = {2018-10-02},
  journaltitle = {Journal of Structural Integrity and Maintenance},
  volume = {3},
  number = {4},
  pages = {233--242},
  publisher = {Taylor \& Francis},
  issn = {2470-5314},
  doi = {10.1080/24705314.2018.1531348},
  abstract = {Blind lifts on congested offshore platform (OP) environments are inherently dangerous because of the substantial presence of spatial conflicts in the crane workspace and the operator’s limited visibility to the load. This research aims to improve operators’ spatial awareness in blind lifts in the OP environment through real-time crane states sensing and visualization. A technical framework is proposed that consists of two sensing modules (i.e., crane motion monitoring and load sway monitoring) and a visualization module. To augment the robustness of the inertial measurement unit (IMU)-based method, a computer vision (CV)-based approach was introduced to track load positions for load sway monitoring. A prototype system was built and tested in an offshore platform to validate the crane motion monitoring and visualization modules. A series of lab and field experiments were conducted to evaluate the accuracy and robustness of CV-based load sway monitoring in control and real-world scenarios. The results from the field and lab tests indicate the proposed framework and methods were able to accurately monitor and visualize the crane states in real-time and thus provide the operator with adequate assistance to identify and mitigate unsafe conditions during blind lifts.},
  keywords = {blind lift,computer vision,Crane operation,sensing,visualization},
  file = {E:\tjustu\研究生\Zotero\storage\4W9HZAX9\Fang 等 - 2018 - Vision-based load sway monitoring to improve crane safety in blind lifts.pdf}
}

@article{fioriniMotionPlanningDynamic1998,
  title = {Motion {{Planning}} in {{Dynamic Environments Using Velocity Obstacles}}},
  author = {Fiorini, Paolo and Shiller, Zvi},
  date = {1998-07-01},
  journaltitle = {The International Journal of Robotics Research},
  volume = {17},
  number = {7},
  pages = {760--772},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/027836499801700706},
  abstract = {This paper presents a method for robot motion planning in dynamic environments. It consists of selecting avoidance maneuvers to avoid static and moving obstacles in the velocity space, based on the cur rent positions and velocities of the robot and obstacles. It is a first- order method, since it does not integrate velocities to yield positions as functions of time.The avoidance maneuvers are generated by selecting robot ve locities outside of the velocity obstacles, which represent the set of robot velocities that would result in a collision with a given obstacle that moves at a given velocity, at some future time. To ensure that the avoidance maneuver is dynamically feasible, the set of avoidance velocities is intersected with the set of admissible velocities, defined by the robot's acceleration constraints. Computing new avoidance maneuvers at regular time intervals accounts for general obstacle trajectories.The trajectory from start to goal is computed by searching a tree of feasible avoidance maneuvers, computed at discrete time intervals. An exhaustive search of the tree yields near-optimal trajectories that either minimize distance or motion time. A heuristic search of the tree is applicable to on-line planning. The method is demonstrated for point and disk robots among static and moving obstacles, and for an automated vehicle in an intelligent vehicle highway system scenario.},
  langid = {english}
}

@article{golcarenarenjiMachinelearningbasedTopviewSafety2022a,
  title = {Machine-Learning-Based Top-View Safety Monitoring of Ground Workforce on Complex Industrial Sites},
  author = {Golcarenarenji, Gelayol and Martinez-Alpiste, Ignacio and Wang, Qi and Alcaraz-Calero, Jose Maria},
  date = {2022-03-01},
  journaltitle = {Neural Computing and Applications},
  shortjournal = {Neural Comput \& Applic},
  volume = {34},
  number = {6},
  pages = {4207--4220},
  issn = {1433-3058},
  doi = {10.1007/s00521-021-06489-3},
  abstract = {Telescopic cranes are powerful lifting facilities employed in construction, transportation, manufacturing and other industries. Since the ground workforce cannot be aware of their surrounding environment during the current crane operations in busy and complex sites, accidents and even fatalities are not avoidable. Hence, deploying an automatic and accurate top-view human detection solution would make significant improvements to the health and safety of the workforce on such industrial operational sites. The proposed method (CraneNet) is a new machine learning empowered solution to increase the visibility of a crane operator in complex industrial operational environments while addressing the challenges of human detection from top-view on a resource-constrained small-form PC to meet the space constraint in the operator’s cabin. CraneNet consists of 4 modified ResBlock-D modules to fulfill the real-time requirements. To increase the accuracy of small humans at high altitudes which is crucial for this use-case, a PAN (Path Aggregation Network) was designed and added to the architecture. This enhances the structure of CraneNet by adding a bottom-up path to spread the low-level information. Furthermore, three output layers were employed in CraneNet to further improve the accuracy of small objects. Spatial Pyramid Pooling (SPP) was integrated at the end of the backbone stage which increases the receptive field of the backbone, thereby increasing the accuracy. The CraneNet has achieved 92.59\% of accuracy at 19 FPS on a portable device. The proposed machine learning model has been trained with the Standford Drone Dataset and Visdrone 2019 to further show the efficacy of the smart crane approach. Consequently, the proposed system is able to detect people in complex industrial operational areas from a distance up to 50 meters between the camera and the person. This system is also applicable to the detection of any other objects from an overhead camera.},
  langid = {english},
  keywords = {安装在吊钩,智能伸缩式起重机,边缘设备},
  file = {E:\tjustu\研究生\Zotero\storage\V6QXHZFW\Golcarenarenji 等 - 2022 - Machine-learning-based top-view safety monitoring of ground workforce on complex industrial sites.pdf}
}

@inproceedings{guDistanceMeasurementTower2012a,
  title = {Distance Measurement for Tower Crane Obstacle Based on Multi-Ultrasonic Sensors},
  booktitle = {2012 {{IEEE International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Gu, Lichen and Kou, Xueqin and Jia, Jia},
  date = {2012-08},
  pages = {1028--1032},
  issn = {2161-8089},
  doi = {10.1109/CoASE.2012.6386344},
  abstract = {Aiming at the anti-collision monitoring of tower crane, the models of state equation and observation equation for obstacle are established, and distance measurement method based on ultrasonic sensor for tower crane obstacle is proposed. According to the multi-sensor information fusion theory and obstacle kinematic model, Kalman filter principle is used to respectively deal with single ultrasonic sensor information and multi-ultrasonic sensor information fusion, then those simulation and experiments results are analyzed and contrasted. The results show that multi-sensor distance measurement is more accurate and stable than single sensor distance measurement, and verify the feasibility and superiority of multi-sensor information fusion theory in tower crane anti-collision applications.},
  eventtitle = {2012 {{IEEE International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  keywords = {Acoustics,Cranes,Distance measurement,Kalman filters,Poles and towers,Sensor fusion},
  file = {E:\tjustu\研究生\Zotero\storage\FV22C7XE\Gu 等 - 2012 - Distance measurement for tower crane obstacle based on multi-ultrasonic sensors.pdf}
}

@inproceedings{hanRealtimeLIDARVision2015,
  title = {A Real-Time {{LIDAR}} and Vision Based Pedestrian Detection System for Unmanned Ground Vehicles},
  booktitle = {2015 3rd {{IAPR Asian Conference}} on {{Pattern Recognition}} ({{ACPR}})},
  author = {Han, Xiaofeng and Lu, Jianfeng and Tai, Ying and Zhao, Chunxia},
  date = {2015-11},
  pages = {635--639},
  issn = {2327-0985},
  doi = {10.1109/ACPR.2015.7486580},
  abstract = {In this work, we present a real-time pedestrian detection system using LIDAR and Vision in-vehicle. We get regions of interest by clustering lidar point clouds and project them onto the images. After that we use black mask to replace those image areas which has no lidar points projected onto. Then we extract HOG and lidar point clouds features and use those features to detect pedestrians by a linear SVM classifier. The main contributions are that we proposed a method that can select ROIs on image automatically and then enhanced the HOG descriptor with the lidar points' projections. Finally we fuse HOG and lidar based features to train a linear SVM to detect pedestrian. The above method we proposed can satisfy real-time requirement. We apply our pedestrian detection system to our own dataset and KITTI dataset, and show that we outperform the primitive HOG based methods.},
  eventtitle = {2015 3rd {{IAPR Asian Conference}} on {{Pattern Recognition}} ({{ACPR}})},
  keywords = {Feature extraction,Image segmentation,Laser radar,Real-time systems,Sensors,Support vector machines,Three-dimensional displays},
  file = {E:\tjustu\研究生\Zotero\storage\MGU5NB95\Han 等 - 2015 - A real-time LIDAR and vision based pedestrian detection system for unmanned ground vehicles.pdf}
}

@article{hwangUltrawideBandTechnology2012,
  title = {Ultra-Wide Band Technology Experiments for Real-Time Prevention of Tower Crane Collisions},
  author = {Hwang, Seokyon},
  date = {2012-03-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  series = {Planning {{Future Cities-Selected}} Papers from the 2010 {{eCAADe Conference}}},
  volume = {22},
  pages = {545--553},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2011.11.015},
  abstract = {Equipment collisions on the jobsites are normally accompanied by significant damages, including fatalities, monetary losses, and delays. This paper presents a method for preventing equipment collision by helping equipment operators improve their situational awareness while operating equipment on site. Noting the need for real-time spatial data, the method incorporates ultra-wideband technology that has been selected through systematic evaluation as the technology that is best suited for the present study. Applying the collision-prevention approaches created in this study, a framework comprised of real-time data collection platform, a visualization module, and a decision module is created. Its technical feasibility for real-time monitoring of equipment operations and assessment of the possibility of collision is examined through lab experiments with a prototype system developed based on the framework. The results of this study prove that integrating precision tracking technology and real-time data analysis can produce tools that will enhance equipment safety.},
  keywords = {Collision,Equipment,Real-time,Safety,Ultra-wideband},
  file = {E:\tjustu\研究生\Zotero\storage\RJ43ZHJT\S0926580511002226.html}
}

@article{jeongVisionBasedProductivityMonitoring2023,
  title = {Vision-{{Based Productivity Monitoring}} of {{Tower Crane Operations}} during {{Curtain Wall Installation Using}} a {{Database-Free Approach}}},
  author = {Jeong, Insoo and Hwang, Jeongbin and Kim, Junghoon and Chi, Seokho and Hwang, Bon-Gang and Kim, Jinwoo},
  date = {2023-07-01},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {37},
  number = {4},
  pages = {04023015},
  publisher = {American Society of Civil Engineers},
  doi = {10.1061/JCCEE5.CPENG-5105},
  abstract = {AbstractTower cranes are generally used in modern construction projects due to their exclusive and flexible performance for material transportation in complex workspaces. Although traditional deep learning vision-based methods have proven their ...},
  langid = {english},
  keywords = {Activity recognition,Curtainwall installation,Database-free (DB-free),Productivity monitoring,Synthetic model,Tower crane,Vision-based},
  file = {E:\tjustu\研究生\Zotero\storage\LYT5Z584\Jeong 等 - 2023 - Vision-Based Productivity Monitoring of Tower Crane Operations during Curtain Wall Installation Usin.pdf}
}

@online{jianDynamicControlBarrier2022,
  title = {Dynamic {{Control Barrier Function-based Model Predictive Control}} to {{Safety-Critical Obstacle-Avoidance}} of {{Mobile Robot}}},
  author = {Jian, Zhuozhu and Yan, Zihong and Lei, Xuanang and Lu, Zihong and Lan, Bin and Wang, Xueqian and Liang, Bin},
  date = {2022-09-18},
  url = {https://arxiv.org/abs/2209.08539v1},
  urldate = {2026-01-08},
  abstract = {This paper presents an efficient and safe method to avoid static and dynamic obstacles based on LiDAR. First, point cloud is used to generate a real-time local grid map for obstacle detection. Then, obstacles are clustered by DBSCAN algorithm and enclosed with minimum bounding ellipses (MBEs). In addition, data association is conducted to match each MBE with the obstacle in the current frame. Considering MBE as an observation, Kalman filter (KF) is used to estimate and predict the motion state of the obstacle. In this way, the trajectory of each obstacle in the forward time domain can be parameterized as a set of ellipses. Due to the uncertainty of the MBE, the semi-major and semi-minor axes of the parameterized ellipse are extended to ensure safety. We extend the traditional Control Barrier Function (CBF) and propose Dynamic Control Barrier Function (D-CBF). We combine D-CBF with Model Predictive Control (MPC) to implement safety-critical dynamic obstacle avoidance. Experiments in simulated and real scenarios are conducted to verify the effectiveness of our algorithm. The source code is released for the reference of the community.},
  langid = {english},
  organization = {arXiv.org}
}

@article{kimAutomatedComplexUrban2016,
  title = {Automated {{Complex Urban Driving}} Based on {{Enhanced Environment Representation}} with {{GPS}}/Map, {{Radar}}, {{Lidar}} and {{Vision}}},
  author = {Kim, Beomjun and Kim, Dongwook and Park, Sungyoul and Jung, Yonghwan and Yi, Kyongsu},
  date = {2016-01-01},
  journaltitle = {IFAC-PapersOnLine},
  shortjournal = {IFAC-PapersOnLine},
  series = {8th {{IFAC Symposium}} on {{Advances}} in {{Automotive Control AAC}} 2016},
  volume = {49},
  number = {11},
  pages = {190--195},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2016.08.029},
  abstract = {This paper describes a fully automated driving algorithm on complex urban roads with guaranteed safety. A serial-production sensor setup is modified as follows: Radar, LiDAR, vision, and GPS/map. The proposed algorithm consists of the following three steps: an environment representation, a safety driving envelope decision, and a motion optimization. An environment representation system consists of three main modules: object classification, vehicle/non-vehicle tracking and map/lane based localization. A motion planning modules derives an optimal motion as a function of time, from the environment representation results. A safety envelope decision module determines the complete driving corridor that leads to the destination while assigning all objects to either the left or right corridor bound. In the case of moving objects such as other traffic participants, their behaviors are anticipated in the near future. A motion optimization module uses the safety envelop as a constraint and computes a trajectory that the vehicle stays in its bounds. The vehicle control module feeds back the pose estimate of the localization module to guide the vehicle along the planned trajectory. The effectiveness of the proposed automated driving algorithm is evaluated via vehicle tests. Test results show the robust performance on an inner-city street scenario.},
  keywords = {Automated driving control algorithm,Automated driving vehicle,Environment representation,Model predictive control,Safe driving envelope decision},
  file = {E:\tjustu\研究生\Zotero\storage\ZFAFFN39\S2405896316313507.html}
}

@article{kimAutomatedComplexUrban2016a,
  title = {Automated {{Complex Urban Driving}} Based on {{Enhanced Environment Representation}} with {{GPS}}/Map, {{Radar}}, {{Lidar}} and {{Vision}}},
  author = {Kim, Beomjun and Kim, Dongwook and Park, Sungyoul and Jung, Yonghwan and Yi, Kyongsu},
  date = {2016-01-01},
  journaltitle = {IFAC-PapersOnLine},
  shortjournal = {IFAC-PapersOnLine},
  series = {8th {{IFAC Symposium}} on {{Advances}} in {{Automotive Control AAC}} 2016},
  volume = {49},
  number = {11},
  pages = {190--195},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2016.08.029},
  abstract = {This paper describes a fully automated driving algorithm on complex urban roads with guaranteed safety. A serial-production sensor setup is modified as follows: Radar, LiDAR, vision, and GPS/map. The proposed algorithm consists of the following three steps: an environment representation, a safety driving envelope decision, and a motion optimization. An environment representation system consists of three main modules: object classification, vehicle/non-vehicle tracking and map/lane based localization. A motion planning modules derives an optimal motion as a function of time, from the environment representation results. A safety envelope decision module determines the complete driving corridor that leads to the destination while assigning all objects to either the left or right corridor bound. In the case of moving objects such as other traffic participants, their behaviors are anticipated in the near future. A motion optimization module uses the safety envelop as a constraint and computes a trajectory that the vehicle stays in its bounds. The vehicle control module feeds back the pose estimate of the localization module to guide the vehicle along the planned trajectory. The effectiveness of the proposed automated driving algorithm is evaluated via vehicle tests. Test results show the robust performance on an inner-city street scenario.},
  keywords = {Automated driving control algorithm,Automated driving vehicle,Environment representation,Model predictive control,Safe driving envelope decision},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\CCVCYKK8\\Kim 等 - 2016 - Automated Complex Urban Driving based on Enhanced Environment Representation with GPSmap, Radar, Li.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\4PKAZMP2\\S2405896316313507.html}
}

@article{kimControlLawsAvoid2019,
  title = {Control Laws to Avoid Collision with Three Dimensional Obstacles Using Sensors},
  author = {Kim, Jonghoek},
  date = {2019-01-15},
  journaltitle = {Ocean Engineering},
  shortjournal = {Ocean Engineering},
  volume = {172},
  pages = {342--349},
  issn = {0029-8018},
  doi = {10.1016/j.oceaneng.2018.11.035},
  abstract = {Collision avoidance in 3D environments is important to the problem of planning safe trajectories for an autonomous vehicle. Existing literature on collision avoidance assumed that obstacle shapes are known a priori and modeled obstacles as spheres or bounding boxes. However, in 3D environments, an obstacle shape is unknown to the autonomous vehicle, and the vehicle detects an obstacle boundary using 3D sensors, such as 3D sonar. In this paper, we introduce control laws for collision avoidance, considering scenarios where a vehicle detects arbitrarily shaped and non-convex obstacles using sensors. Moreover, our control laws are designed considering motion constraints, such as the maximum turn rate and the maximum speed rate of the vehicle. The effectiveness of our control laws is verified using MATLAB simulations.},
  keywords = {3D environment,Arbitrarily shaped obstacle,Collision avoidance,Maximum acceleration,Maximum turn rate},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\8NN6V2AX\\Kim - 2019 - Control laws to avoid collision with three dimensional obstacles using sensors.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\TBLZQUQA\\S0029801818321073.html}
}

@article{kimProximityPredictionMobile2020,
  title = {Proximity {{Prediction}} of {{Mobile Objects}} to {{Prevent Contact-Driven Accidents}} in {{Co-Robotic Construction}}},
  author = {Kim, Daeho and Lee, SangHyun and Kamat, Vineet R.},
  date = {2020-07-01},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {34},
  number = {4},
  pages = {04020022},
  publisher = {American Society of Civil Engineers},
  issn = {1943-5487},
  doi = {10.1061/(ASCE)CP.1943-5487.0000899},
  abstract = {AbstractRobotic solutions have garnered increased attention from the construction industry as an effective means of improving construction safety and productivity. However, in deploying such robots to real fields many safety concerns have remained ...},
  langid = {english},
  keywords = {Autonomous robot,Contact-driven accident,Deep neural network,Proximity prediction,Unmanned aerial vehicle (UAV)},
  file = {E:\tjustu\研究生\Zotero\storage\9E494QN9\Kim 等 - 2020 - Proximity Prediction of Mobile Objects to Prevent Contact-Driven Accidents in Co-Robotic Constructio.pdf}
}

@inproceedings{kimTrajectoryPredictionMobile2019,
  title = {Trajectory {{Prediction}} of {{Mobile Construction Resources Toward Pro-active Struck-by Hazard Detection}}},
  author = {Kim, Daeho and Liu, Meiyin and Lee, Sanghyun and Kamat, Vineet R.},
  date = {2019-05-24},
  location = {Banff, AB, Canada},
  doi = {10.22260/ISARC2019/0131},
  abstract = {In construction, unanticipated struck-by hazards often arise, which have resulted in a significant number of construction fatalities. To address this problem, many studies have attempted to automate proximity monitoring and struck-by hazard detection using various technologies, such as wireless sensors and computer vision methods. While this technology focuses on understanding what is happening as hazards arise, it is not equipped to detect future hazards. In impending situations, detecting current hazards may not provide enough time for workers to take evasive actions. To address this challenge this study develops a trajectory prediction model for mobile construction resources. Specifically, this study conducts hyper-parameter tuning of a deep neural network, called Social Generative Adversarial Network to develop a prediction model capable of predicting more than five seconds. Further, a test on a real construction operations data follows to validate developed models’ trajectory prediction accuracy. As a result, a developed model could achieve promising accuracy: the average displacement error and the final displacement error were 0.78 and 1.27 meters, respectively. The trajectory prediction allows for detecting future hazards, which will support proactive intervention in hazardous situations. It will ultimately contribute to promoting a safer working environment for construction workers.},
  eventtitle = {36th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}}},
  langid = {english},
  file = {E:\tjustu\研究生\Zotero\storage\7JXK4QPR\Kim 等 - 2019 - Trajectory Prediction of Mobile Construction Resources Toward Pro-active Struck-by Hazard Detection.pdf}
}

@inproceedings{kuchkudaIntroductionRayTracing1988,
  title = {An {{Introduction}} to {{Ray Tracing}}},
  booktitle = {Theoretical {{Foundations}} of {{Computer Graphics}} and {{CAD}}},
  author = {Kuchkuda, Roman},
  editor = {Earnshaw, Rae A.},
  date = {1988},
  pages = {1039--1060},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-83539-1_44},
  abstract = {This paper is a practical guide to ray tracing for those familiar with graphics. It consists of a conceptual model of ray tracing, C code for a basic system, and an explanation of how and why the code works.},
  isbn = {978-3-642-83539-1},
  langid = {english},
  keywords = {Boxes,C code,Conceptual Model,LEX,Ray Tracing,Reflection,Shadows,Spheres,Superquadrics,Transparency,Triangles,YACC}
}

@article{kuRoboticTowerCranes2024a,
  title = {Robotic Tower Cranes with Hardware-in-the-Loop: {{Enhancing}} Construction Safety and Efficiency},
  shorttitle = {Robotic Tower Cranes with Hardware-in-the-Loop},
  author = {Ku, Teerapat Kian Xiong and Zuo, Bingran and Ang, Wei Tech},
  date = {2024-12-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {168},
  pages = {105765},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2024.105765},
  abstract = {This paper presents a full suite of Robotic Tower Crane (RTC) technologies that can be seamlessly implemented on traditional saddle-jib tower cranes to boost the construction safety and productivity. The robotisation of tower cranes enables the RTC capabilities of automatic path planning for point-to-point movement, and dynamic obstacle avoidance with re-planning. While the former fast generates the RTC path based on decoupling of vertical and horizontal movements, the latter takes a ‘hoist-first’ approach to prioritise safety. A motion compensation algorithm is developed for multi-step speed control to achieve the exact displacement based on dynamically optimizing the time duration at each planned velocity. The implementation of the RTC system has demonstrated a comprehensive approach that combines laboratory simulations, hardware-in-the-loop testing, and live demos for on-site deployment. A comparative performance and operational time study reveals the RTC's superior precision and consistency over human operators.},
  keywords = {Construction robotics,Heavy machinery automation,Motion planning,Obstacle avoidance,Robotic tower crane},
  file = {E:\tjustu\研究生\Zotero\storage\NBQKUKPZ\S0926580524005016.html}
}

@article{laiCollisionDetectionStrategies2009,
  title = {Collision Detection Strategies for Virtual Construction Simulation},
  author = {Lai, Kuan-Chen and Kang, Shih-Chung},
  date = {2009-10-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {18},
  number = {6},
  pages = {724--736},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2009.02.006},
  abstract = {This research aims at developing a simple and efficient collision detection method to support the rendering of a virtual construction scenario in real time. To expedite the collision detection algorithm, we approximated construction machineries and structural elements on a construction site by using spheres and cylinders. By modeling the objects using outer boundaries, the computational cost for collision detection can be significantly reduced. Using the outer boundary also provides the benefit of ensuring a conservative result (i.e. towards the safer side). VC-COLLIDE, the collision detection algorithm developed in this research, has also been presented. VC-COLLIDE has been implemented and tested by using three typical construction scenarios: small building scenarios (683 objects), large building scenarios (2143 objects) and tall building scenarios (2612 objects). The test results indicate that VC-COLLIDE can complete all the collision checks within 1/20th of a second, the upper bound of real-time refresh time in the three testing environments. We also compared VC-COLLIDE with the collision detection function in Open Dynamic Engine (ODE), a widely used physics engine for real-time visualization. Because VC-COLLIDE is designed specifically for using in a virtual construction scenario, its computational performance is significantly better than ODE.},
  keywords = {Bounding volume box,Collision detection,Construction crane,Construction simulation,Virtual reality},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\657BNX4X\\Lai和Kang - 2009 - Collision detection strategies for virtual construction simulation.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\SQ2VHEJ9\\S0926580509000235.html}
}

@article{leeBIMSensorbasedTower2012g,
  title = {A {{BIM-}} and Sensor-Based Tower Crane Navigation System for Blind Lifts},
  author = {Lee, Ghang and Cho, Joonbeom and Ham, Sungil and Lee, Taekwan and Lee, Gaang and Yun, Seok-Heon and Yang, Hyung-Jun},
  date = {2012-10-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {26},
  pages = {1--10},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2012.05.002},
  abstract = {Tower crane operators often operate a tower crane with blind spots. To solve this problem, video camera systems and anti-collision systems are often deployed. However, the current video camera systems do not provide accurate distance and understanding of the crane's surroundings. A collision-detection system provides location information only as numerical data. This study introduces a newly developed tower crane navigation system that provides three-dimensional information about the building and surroundings and the position of the lifted object in real time using various sensors and a building information modeling (BIM) model. The system quality was evaluated in terms of two aspects, “ease of use” and “usefulness,” based on the Technology Acceptance Model (TAM) theory. The perceived ease of use of the system was improved from the initial 3.2 to 4.4 through an iterative design process. The tower crane navigation system was deployed on an actual construction site for 71days, and the use patterns were video recorded. The results clearly indicated that the tower crane operators relied heavily on the tower crane navigation system during blind lifts (93.33\%) compared to the text-based anti-collision system (6.67\%).},
  keywords = {Building information modeling (BIM),Navigation system,Sensor,Tower crane},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\XJDNPWDT\\Lee 等 - 2012 - A BIM- and sensor-based tower crane navigation system for blind lifts.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\5XGHRBKE\\S0926580512000738.html}
}

@article{leeLasertechnologybasedLiftingpathTracking2009,
  title = {A Laser-Technology-Based Lifting-Path Tracking System for a Robotic Tower Crane},
  author = {Lee, Ghang and Kim, Hong-Hyun and Lee, Chi-Joo and Ham, Sung-Il and Yun, Seok-Heon and Cho, Hunhee and Kim, Bong Keun and Kim, Gu Taek and Kim, Kyunghwan},
  date = {2009-11-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {18},
  number = {7},
  pages = {865--874},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2009.03.011},
  abstract = {As the number of high-rise buildings increases, so does the use of tower cranes, the number of which now tops 3000 per year in Korea. Accordingly, the safety issues of high workspaces and efficiency issues of repeated work arise in the process of lifting materials to high places. As an alternative to traditional tower cranes, we are developing a robotic tower-crane system. By developing a robotic crane system, we expect the productivity to improve by 9.9\%–50\% based on the results of previous studies. In this study, we examine the feasibility of a laser-technology-based lifting-path tracking system for a robotic tower-crane system. There have been efforts to develop a robotic tower crane but they could travel only through preplanned paths or had blind stop problems. We proposed a robotic tower-crane system with a laser device, an encoder, and an accelerometer, and tested the feasibility of the system under indoor, outdoor, and swinging conditions. In the process, we developed a software application to receive and record data from the laser device. The test results showed the feasibility of a proposed lifting-path tracking system for a robotic tower crane under various outdoor conditions. Several limitations have been also recognized.},
  keywords = {Automated lifting system,Laser distance measurement,Robotic tower crane},
  file = {E:\tjustu\研究生\Zotero\storage\KVFDVPH2\S092658050900051X.html}
}

@article{lekicAutomotiveRadarCamera2019,
  title = {Automotive Radar and Camera Fusion Using {{Generative Adversarial Networks}}},
  author = {Lekic, Vladimir and Babic, Zdenka},
  date = {2019-07-01},
  journaltitle = {Computer Vision and Image Understanding},
  shortjournal = {Computer Vision and Image Understanding},
  volume = {184},
  pages = {1--8},
  issn = {1077-3142},
  doi = {10.1016/j.cviu.2019.04.002},
  abstract = {Radar sensors are considered to be very robust under harsh weather and poor lighting conditions. Largely owing to this reputation, they have found broad application in driver assistance and highly automated driving systems. However, radar sensors have considerably lower precision than cameras. Low sensor precision causes ambiguity in the human interpretation of the measurement data and makes the data labeling process difficult and expensive. On the other hand, without a large amount of high-quality labeled training data, it is difficult, if not impossible, to ensure that the supervised machine learning models can predict, classify, or otherwise analyze the phenomenon of interest with the required accuracy. This paper presents a method for fusing the radar sensor measurements with the camera images. A proposed fully-unsupervised machine learning algorithm converts the radar sensor data to artificial, camera-like, environmental images. Through such data fusion, the algorithm produces more consistent, accurate, and useful information than that provided solely by the radar or the camera. The essential point of the work is the proposal of a novel Conditional Multi-Generator Generative Adversarial Network (CMGGAN) that, being conditioned on the radar sensor measurements, can produce visually appealing images that qualitatively and quantitatively contain all environment features detected by the radar sensor.},
  keywords = {Camera,Computer vision,Driver assistance,Generative Adversarial Networks,Highly automated driving,Image processing,Radar,Unsupervised learning},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\HACXRCIS\\Lekic和Babic - 2019 - Automotive radar and camera fusion using Generative Adversarial Networks.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\MMBNQ29A\\S1077314219300530.html}
}

@inproceedings{nadarIntelligentSystemMonitoring2013,
  title = {An {{Intelligent System}} for {{Monitoring Tower Cranes}} on {{Construction Sites}}},
  author = {Nadar, M. A. and Awakian, C. A. and Khoury, H. K.},
  date = {2013-08-11},
  location = {Montreal, Canada},
  doi = {10.22260/ISARC2013/0139},
  abstract = {Harsh and dynamic construction sites are generally equipped with cranes in order to rapidly and conveniently move heavy loads from one location to the other. If not properly inspected and managed, this operation can be very hazardous and lead to accidents. As such, a reliable and self-contained monitoring system that can update construction and safety personnel about the status of the crane, the weight of the load lifted, the location of the boom with respect to nearby buildings and other tower cranes, and the weather conditions under which the crane is operating, is deemed necessary. This can lead to significant time and cost savings as well as safety and productivity improvement due to the accuracy and immediacy of relevant on-site crane information delivery. This paper takes the initial steps and presents research targeted at evaluating the capability of wireless sensor networks (WSN) for monitoring tower crane operations in construction environments. A reliable long range WSN system is implemented and information is obtained from various special-purpose sensors (temperature, wind, proximity, etc.) mounted on special motes that relay data to and from each other and a central hub. The latter continuously monitors and manages network performance and relays incoming data to the host application. This application, in turn, displays the received data, and maps it onto a user-friendly visualization scheme, triggering alarms when a set of pre-programmed rules and safety conditions are crossed. The components of the proposed system have been tested through proof of concept experiments and preliminary results highlighted the potential of WSN systems for improving monitoring of tower cranes and reducing related accidents on construction sites, especially in Lebanon and the Middle East region where safety precautions are usually not properly implemented.},
  eventtitle = {30th {{International Symposium}} on {{Automation}} and {{Robotics}} in {{Construction}} and {{Mining}}; {{Held}} in Conjunction with the 23rd {{World Mining Congress}}},
  langid = {english},
  file = {E:\tjustu\研究生\Zotero\storage\QCL6M4MW\Nadar 等 - 2013 - An Intelligent System for Monitoring Tower Cranes on Construction Sites.pdf}
}

@article{nadimiCalibrationValidationNew2016,
  title = {Calibration and Validation of a New Time-Based Surrogate Safety Measure Using Fuzzy Inference System},
  author = {Nadimi, Navid and Behbahani, Hamid and Shahbazi, HamidReza},
  date = {2016-02-01},
  journaltitle = {Journal of Traffic and Transportation Engineering (English Edition)},
  shortjournal = {Journal of Traffic and Transportation Engineering (English Edition)},
  volume = {3},
  number = {1},
  pages = {51--58},
  issn = {2095-7564},
  doi = {10.1016/j.jtte.2015.09.004},
  abstract = {Surrogate safety measures (SSM) are suitable tools to detect dangerous situations. These indicators can be applied as a warning strategy in collision avoidance systems (CAS). Time-to-collision (TTC) and post-encroachment time (PET) are two important time-based SSM that identify the probability of a rear-end collision. TTC refers to the imminent danger, and PET implies the potential danger. However, sometimes the results from each indicator are inconsistent. An appropriate warning strategy for CAS can be developed using a new index that combines the properties of both TTC and PET. For this purpose, a new mixed index (MI) is proposed. In order to develop this MI, three main microscopic parameters, clearance, speed and the relative speed, are simultaneously applied to the leading vehicle. To calibrate MI, based on a fuzzy inference system (FIS), a value would be determined by a combination of TTC and PET at each instant and then by regression analysis the model parameters would be determined. Finally, MI, TTC and PET values for real car-following scenarios on the I-80 freeway are determined and compared. The results show that MI may be more suitable in detecting the rear-end collision risk within the proper time and with less errors.},
  keywords = {Fuzzy inference system,Post-encroachment time,Surrogate safety measure,Time-to-collision},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\A337WHIB\\Nadimi 等 - 2016 - Calibration and validation of a new time-based surrogate safety measure using fuzzy inference system.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\MHSSE2KS\\S2095756415200153.html}
}

@inproceedings{ouyangCGANsBasedSceneReconstruction2017,
  title = {A {{cGANs-Based Scene Reconstruction Model Using Lidar Point Cloud}}},
  booktitle = {2017 {{IEEE International Symposium}} on {{Parallel}} and {{Distributed Processing}} with {{Applications}} and 2017 {{IEEE International Conference}} on {{Ubiquitous Computing}} and {{Communications}} ({{ISPA}}/{{IUCC}})},
  author = {Ouyang, Zhenchao and Liu, Yu and Zhang, Changjie and Niu, Jianwei},
  date = {2017-12},
  pages = {1107--1114},
  doi = {10.1109/ISPA/IUCC.2017.00167},
  abstract = {Road scene reconstruction is a fundamental and crucial module at the perception phase for autonomous vehicles, and will influence the later phase, such as object detection, motion planing and path planing. Traditionally, self-driving car uses Lidar, camera or fusion of the two kinds of sensors for sensing the environment. However, single Lidar or camera-based approaches will miss crucial information, and the fusion-based approaches often consume huge computing resources. We firstly propose a conditional Generative Adversarial Networks (cGANs)-based deep learning model that can rebuild rich semantic scene images from upsampled Lidar point clouds only. This makes it possible to remove cameras to reduce resource consumption and improve the processing rate. Simulation on the KITTI dataset also demonstrates that our model can reestablish color imagery from a single Lidar point cloud, and is effective enough for real time sensing on autonomous driving vehicles.},
  eventtitle = {2017 {{IEEE International Symposium}} on {{Parallel}} and {{Distributed Processing}} with {{Applications}} and 2017 {{IEEE International Conference}} on {{Ubiquitous Computing}} and {{Communications}} ({{ISPA}}/{{IUCC}})},
  keywords = {autonomous vehicle,Cameras,cGANs,Color,Image reconstruction,Laser radar,Lidar point cloud,scene reconstruction,Sensors,Solid modeling,Three-dimensional displays,upsampling},
  file = {E:\tjustu\研究生\Zotero\storage\ARPHH8YS\Ouyang 等 - 2017 - A cGANs-Based Scene Reconstruction Model Using Lidar Point Cloud.pdf}
}

@article{parkCollisionAvoidanceHexacopter2020,
  title = {Collision {{Avoidance}} of {{Hexacopter UAV Based}} on {{LiDAR Data}} in {{Dynamic Environment}}},
  author = {Park, Jongho and Cho, Namhoon},
  date = {2020-01},
  journaltitle = {Remote Sensing},
  volume = {12},
  number = {6},
  pages = {975},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs12060975},
  abstract = {A reactive three-dimensional maneuver strategy for a multirotor Unmanned Aerial Vehicle (UAV) is proposed based on the collision cone approach to avoid potential collision with a single moving obstacle detected by an onboard sensor. A Light Detection And Ranging (LiDAR) system is assumed to be mounted on a hexacopter to obtain the obstacle information from the collected point clouds. The collision cone approach is enhanced to appropriately deal with the moving obstacle with the help of a Kalman filter. The filter estimates the position, velocity, and acceleration of the obstacle by using the LiDAR data as the associated measurement. The obstacle state estimate is utilized to predict the future trajectories of the moving obstacle. The collision detection and obstacle avoidance maneuver decisions are made considering the predicted trajectory of the obstacle. Numerical simulations, including a Monte Carlo campaign, are conducted to verify the performance of the proposed collision avoidance algorithm.},
  langid = {english},
  keywords = {collision avoidance,dynamic environment,guidance algorithm,hexacopter,unmanned aerial vehicle}
}

@inproceedings{pfreundschuhDynamicObjectAware2021,
  title = {Dynamic {{Object Aware LiDAR SLAM}} Based on {{Automatic Generation}} of {{Training Data}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Pfreundschuh, Patrick and Hendrikx, Hubertus F.C. and Reijgwart, Victor and Dubé, Renaud and Siegwart, Roland and Cramariuc, Andrei},
  date = {2021-05},
  pages = {11641--11647},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9560730},
  abstract = {Highly dynamic environments, with moving objects such as cars or humans, can pose a performance challenge for LiDAR SLAM systems that assume largely static scenes. To overcome this challenge and support the deployment of robots in real world scenarios, we propose a complete solution for a dynamic object aware LiDAR SLAM algorithm. This is achieved by leveraging a real-time capable neural network that can detect dynamic objects, thus allowing our system to deal with them explicitly. To efficiently generate the necessary training data which is key to our approach, we present a novel end-to-end occupancy grid based pipeline that can automatically label a wide variety of arbitrary dynamic objects. Our solution can thus generalize to different environments without the need for expensive manual labeling and at the same time avoids assumptions about the presence of a predefined set of known objects in the scene. Using this technique, we automatically label over 12000 LiDAR scans collected in an urban environment with a large amount of pedestrians and use this data to train a neural network, achieving an average segmentation IoU of 0.82. We show that explicitly dealing with dynamic objects can improve the LiDAR SLAM odometry performance by 39.6\% while yielding maps which better represent the environments. A supplementary video1 as well as our test data2 are available online.},
  eventtitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  keywords = {Heuristic algorithms,Laser radar,Neural networks,Pipelines,Simultaneous localization and mapping,Three-dimensional displays,Urban areas},
  file = {E:\tjustu\研究生\Zotero\storage\QQD5CDKG\Pfreundschuh 等 - 2021 - Dynamic Object Aware LiDAR SLAM based on Automatic Generation of Training Data.pdf}
}

@article{priceMultisensordrivenRealtimeCrane2021,
  title = {Multisensor-Driven Real-Time Crane Monitoring System for Blind Lift Operations: {{Lessons}} Learned from a Case Study},
  shorttitle = {Multisensor-Driven Real-Time Crane Monitoring System for Blind Lift Operations},
  author = {Price, Leon C. and Chen, Jingdao and Park, Jisoo and Cho, Yong K.},
  date = {2021-04-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {124},
  pages = {103552},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2021.103552},
  abstract = {Crane operators are often unable to identify collision hazards due to limited visibility during blind lifts or when operating under cluttered conditions. This paper presents a multisensor-driven real-time crane monitoring system consisting of load tracking, obstacle detection, worker detection, collision warning, and 3D visualization modules. A combination of encoders, vision, and laser scanning systems is used to reconstruct a 3D workspace model of the crane environment and provide real-time spatial feedback to the operator. Field experimentation was carried out at an outdoor crane manufacturing facility under different blind lift scenarios. Results showed that the encoder-based load positioning system has a mean height estimation error within 0.33~m, the vision-based load positioning system has a mean centroid error of 0.454~m, and the worker detection system has a mean centroid error of 0.023~m. This study also provided important findings in terms of challenges and limitations in implementing a real-world crane monitoring system.},
  keywords = {Blind lift,Computer vision,Crane,Real-time,Sensing,Visualization},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\HRTC6IP4\\Price 等 - 2021 - Multisensor-driven real-time crane monitoring system for blind lift operations Lessons learned from.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\A54SSCNN\\S0926580521000030.html}
}

@book{rashidCouplingRiskAttitude2017,
  title = {Coupling Risk Attitude and Motion Data Mining in a Preemtive Construction Safety Framework},
  author = {Rashid, Khandakar and Datta, Songjukta and Behzadan, Amir},
  date = {2017-12-01},
  pages = {2424},
  doi = {10.1109/WSC.2017.8247971},
  pagetotal = {2413},
  file = {E:\tjustu\研究生\Zotero\storage\MI6B65EJ\Rashid 等 - 2017 - Coupling risk attitude and motion data mining in a preemtive construction safety framework.pdf}
}

@article{schoolofgeomatricsandurbanspatialinformationbeijinguniversityofcivilengineeringandarchitecturebeijingchina.miaowangiswithschoolofcivilandtransportationengineeringbeijinguniversityofcivilengineeringandarchitecturebeijingchina.ResearchIntelligentAnticollision2019,
  title = {Research on {{Intelligent Anti-collision Monitoring}} for {{Construction Tower Crane Group Based}} on {{GNSS Sensors}}},
  author = {{School of Geomatrics and Urban Spatial Information, Beijing University of Civil Engineering and Architecture, Beijing, China. Miao Wang is with School of Civil and Transportation Engineering, Beijing University of Civil Engineering and Architecture, Beijing, China.} and Zhou, Mingduan and Wang, Qianlin and Tan, Hongjie and Wang, Miao},
  date = {2019},
  journaltitle = {International Journal of Computer and Communication Engineering},
  shortjournal = {IJCCE},
  volume = {8},
  number = {4},
  pages = {169--177},
  issn = {20103743},
  doi = {10.17706/IJCCE.2019.8.4.169-177},
  abstract = {A novel anti-collision monitoring method is proposed based on GNSS single-epoch positioning technology via high-precision carrier phase observations, which is applied to intelligent anti-collision monitoring for construction tower crane group. GNSS-based anti-collision monitoring principles are given in detail. A set of GNSS-based anti-collision monitoring auxiliary system named as GNSS\_ACS for construction tower crane group is designed and developed. It can realize three kinds of alarm monitoring function consist of C-level, B-level and A-level respectively. The monitoring accuracy in the GNSS\_ACS system ,for 600 consecutive epochs of the rover station such as rover\_1727, the min-error of N-RMS is 0.007m, the max-error of N-RMS is 0.012m and the avg-error of N-RMS is 0.010m; the min- error of E-RMS is 0.005m, the max-error of E-RMS is 0.008m and the avg-error of E-RMS is 0.011m; the min-error of U-RMS is 0.015m, the max-error of U-RMS is 0.029m and the avg-error of U-RMS is 0.022m, is obtained in cm-level which verifies the effectiveness and feasibility of the proposed solutions in the experimental results. It can provide a new solution for intelligent anti-collision monitoring of construction tower crane group.},
  langid = {english},
  file = {E:\tjustu\研究生\Zotero\storage\PLVD7D9A\527-MEC303-libre.pdf}
}

@article{shapiraCranesBuildingConstruction2007,
  title = {Cranes for {{Building Construction Projects}}},
  author = {Shapira, Aviad and Lucko, Gunnar and Schexnayder, Clifford J.},
  date = {2007-09-01},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {133},
  number = {9},
  pages = {690--700},
  publisher = {American Society of Civil Engineers},
  issn = {0733-9364},
  doi = {10.1061/(ASCE)0733-9364(2007)133:9(690)},
  abstract = {Cranes have come to symbolize building construction itself. They perform indispensable services in moving materials and components vertically and horizontally. Used since antiquity, their history is interrelated with the development of new power sources ...},
  langid = {english},
  keywords = {Construction equipment,Construction management,Cranes,History}
}

@article{shapiraIdentificationAnalysisFactors2009,
  title = {Identification and {{Analysis}} of {{Factors Affecting Safety}} on {{Construction Sites}} with {{Tower Cranes}}},
  author = {Shapira, Aviad and Lyachin, Beny},
  date = {2009-01-01},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {135},
  number = {1},
  pages = {24--33},
  publisher = {American Society of Civil Engineers},
  issn = {0733-9364},
  doi = {10.1061/(ASCE)0733-9364(2009)135:1(24)},
  abstract = {Tower cranes are the centerpiece of production on today’s typical building construction sites. Tower cranes hoist and transport a variety of loads near and above people, working under crowded conditions, occasionally with overlapping work zones, and often ...},
  langid = {english},
  keywords = {Accidents,Construction sites,Cranes,Hazards,Human factors,Safety},
  file = {E:\tjustu\研究生\Zotero\storage\HRYZL8JR\Shapira 和 Lyachin - 2009 - Identification and Analysis of Factors Affecting S.pdf}
}

@article{shapiraVisionSystemTower2008a,
  title = {Vision {{System}} for {{Tower Cranes}}},
  author = {Shapira, Aviad and Rosenfeld, Yehiel and Mizrahi, Israel},
  date = {2008-05-01},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {134},
  number = {5},
  pages = {320--332},
  publisher = {American Society of Civil Engineers},
  issn = {0733-9364},
  doi = {10.1061/(ASCE)0733-9364(2008)134:5(320)},
  abstract = {Operators of tower cranes enjoy a bird’s eye view of the site, which undeniably contributes to work safety and efficiency. Yet their work often involves blind lifts, as well as other viewing difficulties, that impede full utilization of the potential ...},
  langid = {english},
  keywords = {Construction equipment,Construction sites,Cranes,Innovation,Productivity,Safety},
  file = {E:\tjustu\研究生\Zotero\storage\BTV5QD34\Shapira 等 - 2008 - Vision System for Tower Cranes.pdf}
}

@article{siebertMobile3DMapping2014,
  title = {Mobile {{3D}} Mapping for Surveying Earthwork Projects Using an {{Unmanned Aerial Vehicle}} ({{UAV}}) System},
  author = {Siebert, Sebastian and Teizer, Jochen},
  date = {2014-05-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {41},
  pages = {1--14},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2014.01.004},
  abstract = {Unmanned Aerial Vehicle (UAV) systems as a data acquisition platform and as a measurement instrument are becoming attractive for many surveying applications in civil engineering. Their performance, however, is not well understood for these particular tasks. The scope of the presented work is the performance evaluation of a UAV system that was built to rapidly and autonomously acquire mobile three-dimensional (3D) mapping data. Details to the components of the UAV system (hardware and control software) are explained. A novel program for photogrammetric flight planning and its execution for the generation of 3D point clouds from digital mobile images is explained. A performance model for estimating the position error was developed and tested in several realistic construction environments. Test results are presented as they relate to large excavation and earth moving construction sites. The experiences with the developed UAV system are useful to researchers or practitioners in need for successfully adapting UAV technology for their application(s).},
  keywords = {3D range point cloud generation and mapping,Airplane and helicopters,Autonomous vision-based infrastructure sensing,Efficiency productivity and safety in geomatics and surveying,Global positioning system (GPS),Laser scanning,Photogrammetry,Remotely piloted vehicles (RPV),Robotic total station (RTS),Unmanned aerial vehicle (UAV) systems (UAS)},
  file = {E:\tjustu\研究生\Zotero\storage\TVNVQPIQ\S0926580514000193.html}
}

@article{sleimanSensorBasedPlanningTool2016a,
  title = {Sensor-{{Based Planning Tool}} for {{Tower Crane Anti-Collision Monitoring}} on {{Construction Sites}}},
  author = {Sleiman, Jean-Pierre and Zankoul, Emile and Khoury, Hiam and Hamzeh, Farook},
  date = {2016-05-24},
  pages = {2624--2632},
  publisher = {American Society of Civil Engineers},
  doi = {10.1061/9780784479827.261},
  langid = {english},
  file = {E:\tjustu\研究生\Zotero\storage\XE4NTH2D\Sleiman 等 - 2016 - Sensor-Based Planning Tool for Tower Crane Anti-Collision Monitoring on Construction Sites.pdf}
}

@inproceedings{sunkaraCollisionAvoidanceLaws2016,
  title = {Collision Avoidance Laws for Objects with Arbitrary Shapes},
  booktitle = {2016 {{IEEE}} 55th {{Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Sunkara, Vishwamithra and Chakravarthy, Animesh},
  date = {2016-12},
  pages = {5158--5164},
  doi = {10.1109/CDC.2016.7799058},
  abstract = {In the collision avoidance problem, it is a common practice to approximate the shapes of the robots and obstacles by circles or spheres. However, such approximations can be overly conservative when the objects are more elongated in one direction when compared to another, and/or non-convex. This paper develops two analytical collision avoidance laws, which do not require any approximations to the object shapes. These laws are based on the collision cone approach which has previously been used to develop exact collision conditions for objects with arbitrary shapes, moving on a plane. The first collision avoidance law governs the magnitude of the acceleration (applied at an arbitrary angle), while the second collision avoidance law governs the direction of the acceleration (applied with a magnitude of 0 or 1). The effect of time delays on the performance of the laws is analyzed. Simulation results are presented to demonstrate the working of these collision avoidance laws.},
  eventtitle = {2016 {{IEEE}} 55th {{Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  keywords = {Collision avoidance,Geometry,Robot sensing systems,Shape,Trajectory},
  file = {E:\tjustu\研究生\Zotero\storage\CS37YEQZ\Sunkara和Chakravarthy - 2016 - Collision avoidance laws for objects with arbitrary shapes.pdf}
}

@article{tangComparativeReviewMultimodal2023,
  title = {A Comparative Review on Multi-Modal Sensors Fusion Based on Deep Learning},
  author = {Tang, Qin and Liang, Jing and Zhu, Fangqi},
  date = {2023-12-01},
  journaltitle = {Signal Processing},
  shortjournal = {Signal Processing},
  volume = {213},
  pages = {109165},
  issn = {0165-1684},
  doi = {10.1016/j.sigpro.2023.109165},
  abstract = {The wide deployment of multi-modal sensors in various areas generates vast amounts of data with characteristics of high volume, wide variety, and high integrity. However, traditional data fusion methods face immense challenges when dealing with multi-modal data containing abundant intermodality and cross-modality information. Deep learning has the ability to automatically extract and understand the potential association of multi-modal information. Despite this, there is a lack of a comprehensive review of the inherent inference mechanisms of deep learning for multi-modal sensor fusion. This work investigates up-to-date developments in multi-modal sensor fusion via deep learning to provide a broad picture of data fusion needs and technologies. It compares the characteristics of multi-modal data for various sensors, summarizes background concepts about data fusion and deep learning, and carefully reviews a large number of investigations in four inference mechanisms: adaptive learning, deep generative, deep discriminative, and algorithms unrolling. The pros and cons of the above methodologies are presented, and several popular application domains are discussed, including medical imaging, autonomous driving, remote sensing, and robotics. A large collection of multi-modal datasets published in recent years is presented, and several tables that quantitatively compare and summarize the performance of fusion algorithms are provided. Finally, by acknowledging the limitations of current research, we establish potential open challenges and future directions as guidance for deep learning-based multi-sensor fusion.},
  keywords = {Deep learning,Inference mechanisms,Multi-model data fusion},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\GXQKQWCM\\Tang 等 - 2023 - A comparative review on multi-modal sensors fusion based on deep learning.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\7M87MDAW\\S0165168423002396.html}
}

@article{tangVideoBasedMotionTrajectory2020,
  title = {Video-{{Based Motion Trajectory Forecasting Method}} for {{Proactive Construction Safety Monitoring Systems}}},
  author = {Tang, Shuai and Golparvar-Fard, Mani and Naphade, Milind and Gopalakrishna, Murali M.},
  date = {2020-11-01},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {34},
  number = {6},
  pages = {04020041},
  publisher = {American Society of Civil Engineers},
  issn = {1943-5487},
  doi = {10.1061/(ASCE)CP.1943-5487.0000923},
  abstract = {AbstractFalls, struck-bys, and caught-in/betweens are among the most common types of fatal accidents on construction sites. Despite their significance, the majority of today’s accident prevention programs react passively to situations in which workers or ...},
  langid = {english},
  file = {E:\tjustu\研究生\Zotero\storage\6T2FARF6\Tang 等 - 2020 - Video-Based Motion Trajectory Forecasting Method for Proactive Construction Safety Monitoring System.pdf}
}

@inproceedings{vandenbergReciprocalVelocityObstacles2008,
  title = {Reciprocal {{Velocity Obstacles}} for Real-Time Multi-Agent Navigation},
  booktitle = {2008 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {family=Berg, given=Jur, prefix=van den, useprefix=true and Lin, Ming and Manocha, Dinesh},
  date = {2008-05},
  pages = {1928--1935},
  issn = {1050-4729},
  doi = {10.1109/ROBOT.2008.4543489},
  abstract = {In this paper, we propose a new concept — the ‘Reciprocal Velocity Obstacle’— for real-time multi-agent navigation. We consider the case in which each agent navigates independently without explicit communication with other agents. Our formulation is an extension of the Velocity Obstacle concept [3], which was introduced for navigation among (passively) moving obstacles. Our approach takes into account the reactive behavior of the other agents by implicitly assuming that the other agents make a similar collision-avoidance reasoning. We show that this method guarantees safe and oscillation-free motions for each of the agents. We apply our concept to navigation of hundreds of agents in densely populated environments containing both static and moving obstacles, and we show that real-time and scalable performance is achieved in such challenging scenarios.},
  eventtitle = {2008 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  keywords = {Assembly systems,Centralized control,Collision avoidance,Communication system control,Contracts,Motion control,Multiagent systems,Navigation,Robotics and automation,USA Councils},
  file = {E:\tjustu\研究生\Zotero\storage\3E8XCLBX\van den Berg 等 - 2008 - Reciprocal Velocity Obstacles for real-time multi-agent navigation.pdf}
}

@article{wangMultiSensorFusionAutomated2020,
  title = {Multi-{{Sensor Fusion}} in {{Automated Driving}}: {{A Survey}}},
  shorttitle = {Multi-{{Sensor Fusion}} in {{Automated Driving}}},
  author = {Wang, Zhangjing and Wu, Yu and Niu, Qingqing},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {2847--2868},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2962554},
  abstract = {With the significant development of practicability in deep learning and the ultra-high-speed information transmission rate of 5G communication technology will overcome the barrier of data transmission on the Internet of Vehicles, automated driving is becoming a pivotal technology affecting the future industry. Sensors are the key to the perception of the outside world in the automated driving system and whose cooperation performance directly determines the safety of automated driving vehicles. In this survey, we mainly discuss the different strategies of multi-sensor fusion in automated driving in recent years. The performance of conventional sensors and the necessity of multi-sensor fusion are analyzed, including radar, LiDAR, camera, ultrasonic, GPS, IMU, and V2X. According to the differences in the latest studies, we divide the fusion strategies into four categories and point out some shortcomings. Sensor fusion is mainly applied for multi-target tracking and environment reconstruction. We discuss the method of establishing a motion model and data association in multi-target tracking. At the end of the paper, we analyzed the deficiencies in the current studies and put forward some suggestions for further improvement in the future. Through this investigation, we hope to analyze the current situation of multi-sensor fusion in the automated driving process and provide more efficient and reliable fusion strategies.},
  keywords = {Automated driving,Cameras,data association,deep learning,environmental reconstruction,intent analysis,Laser radar,multi-sensor fusion strategy,multi-target tracking,Sensor fusion,Sensor phenomena and characterization,Sensor systems},
  file = {E:\tjustu\研究生\Zotero\storage\8WYHWHBF\Wang 等 - 2020 - Multi-Sensor Fusion in Automated Driving A Survey.pdf}
}

@article{wangSafetyWarningAlgorithm2021,
  title = {A {{Safety Warning Algorithm Based}} on {{Axis Aligned Bounding Box Method}} to {{Prevent Onsite Accidents}} of {{Mobile Construction Machineries}}},
  author = {Wang, Cynthia Changxin and Wang, Mudan and Sun, Jun and Mojtahedi, Mohammad},
  date = {2021-01},
  journaltitle = {Sensors},
  volume = {21},
  number = {21},
  pages = {7075},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s21217075},
  abstract = {Mobile construction machineries are accident-prone on a dynamic construction site, as the site environment is constantly changing and continuous safety monitoring by human beings is impossible. These accidents usually happen in the form of machinery overturning or collapsing into risk areas, including the foundation pit, slopes, or soft soil area. Therefore, preventing mobile construction machineries from entering risk areas is the key. However, currently, there is a lack of practical safety management techniques to achieve this. Utilizing a wireless sensor device to collect the location information of mobile construction machineries, this research develops a safety warning algorithm to prevent the machineries moving into risk area and reduces onsite overturning or collapsing accidents. A modified axis aligned bounding box method is proposed according to the movement patterns of mobile construction machineries, and the warning algorithm is developed based on the onsite safety management regulations. The algorithm is validated in a real case simulation when machinery enters the warning zone. The simulation results showed that the overall algorithm combining the location sensing technology and the modified bounding box method could detect risk and give warnings in a timely manner. This algorithm can be implemented for the safety monitoring of mobile construction machineries in daily onsite management.},
  langid = {english},
  keywords = {accident prevention,axis aligned bounding box method,construction machinery,location sensing technology,safety warning algorithm}
}

@article{weiLiDARCameraDetection2018,
  title = {{{LiDAR}} and {{Camera Detection Fusion}} in a {{Real-Time Industrial Multi-Sensor Collision Avoidance System}}},
  author = {Wei, Pan and Cagle, Lucas and Reza, Tasmia and Ball, John and Gafford, James},
  date = {2018-06},
  journaltitle = {Electronics},
  volume = {7},
  number = {6},
  pages = {84},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics7060084},
  abstract = {Collision avoidance is a critical task in many applications, such as ADAS (advanced driver-assistance systems), industrial automation and robotics. In an industrial automation setting, certain areas should be off limits to an automated vehicle for protection of people and high-valued assets. These areas can be quarantined by mapping (e.g., GPS) or via beacons that delineate a no-entry area. We propose a delineation method where the industrial vehicle utilizes a LiDAR (Light Detection and Ranging) and a single color camera to detect passive beacons and model-predictive control to stop the vehicle from entering a restricted space. The beacons are standard orange traffic cones with a highly reflective vertical pole attached. The LiDAR can readily detect these beacons, but suffers from false positives due to other reflective surfaces such as worker safety vests. Herein, we put forth a method for reducing false positive detection from the LiDAR by projecting the beacons in the camera imagery via a deep learning method and validating the detection using a neural network-learned projection from the camera to the LiDAR space. Experimental data collected at Mississippi State University’s Center for Advanced Vehicular Systems (CAVS) shows the effectiveness of the proposed system in keeping the true detection while mitigating false positives.},
  langid = {english},
  keywords = {ADAS,camera,deep learning,fusion,LiDAR,multi-sensor},
  file = {E:\tjustu\研究生\Zotero\storage\PA86KYEE\Wei 等 - 2018 - LiDAR and Camera Detection Fusion in a Real-Time Industrial Multi-Sensor Collision Avoidance System.pdf}
}

@inproceedings{wuLiDARCameraSensor2017,
  title = {{{LiDAR}}/Camera Sensor Fusion Technology for Pedestrian Detection},
  booktitle = {2017 {{Asia-Pacific Signal}} and {{Information Processing Association Annual Summit}} and {{Conference}} ({{APSIPA ASC}})},
  author = {Wu, Tai-En and Tsai, Chia-Chi and Guo, Jiun-In},
  date = {2017-12},
  pages = {1675--1678},
  doi = {10.1109/APSIPA.2017.8282301},
  abstract = {Nowadays, the machine learning for object detection is growing popular and widely adopted in many fields, such as surveillance, automotive, passenger flow analysis, etc. This paper focuses on the research of Lidar/camera sensor fusion technology for pedestrian detection to ensure extremely high detection accuracy. In order to reduce the false-positive rate and the object occlusion problem, which usually happened in camera-based pedestrian detection, we use 3D point cloud returning from Lidar depth sensor to do the further examination on the object's shape. The proposed Lidar/camera sensor fusion design complements the advantage and disadvantage of two sensors such that it is more stable in detection than others. The region proposal is given from both sensors, and candidate from two sensors are also going to the second classification for double checking. It maximums the detection rate and achieves average 99.16\% detection accuracy for pedestrian detection.},
  eventtitle = {2017 {{Asia-Pacific Signal}} and {{Information Processing Association Annual Summit}} and {{Conference}} ({{APSIPA ASC}})},
  keywords = {Automotive engineering,Conferences,Laser radar,Object detection,Sensor fusion,Surveillance,Three-dimensional displays},
  file = {E:\tjustu\研究生\Zotero\storage\BHQ3MEF2\Wu 等 - 2017 - LiDARcamera sensor fusion technology for pedestrian detection.pdf}
}

@article{wuLocationBasedService2013a,
  title = {A Location Based Service Approach for Collision Warning Systems in Concrete Dam Construction},
  author = {Wu, Hao and Tao, Jing and Li, Xinping and Chi, Xiuwen and Li, Hua and Hua, Xianghong and Yang, Ronghua and Wang, Sheng and Chen, Nan},
  date = {2013-01-01},
  journaltitle = {Safety Science},
  shortjournal = {Safety Science},
  volume = {51},
  number = {1},
  pages = {338--346},
  issn = {0925-7535},
  doi = {10.1016/j.ssci.2012.08.006},
  abstract = {This paper describes a location based service approach for the prevention of large haulage equipment collision accidents involving concrete buckets during dam construction phase. A review has been provided on the background relating to common collision avoidance on construction sites. It is of upmost importance to establish a collision warning system in a pro-active real-time mode for the specific environment of dam construction. The location based service combines wireless communications, GPS and GIS technologies for a continuous operation to address this problem. A system design is proposed with a location based defined function. In this paper, the design algorithms for warning and guiding in different operation modes are detailed and discussed. They are formulated to automatically detect any potential hazards, alert drivers, thereby avoiding collision, and to provide reliable navigation. A set of preliminary tests show that the system prototype is a feasible option in fulfilling the collision warning function, as well as a practicable option when linked with automation and visualization in the dam construction process. Development of such an integrated technology assisted location based service approach to a collision warning system has a significant impact on the application of the safety systems on construction sites, and also promotes efficiency management in the project.},
  keywords = {Collision warning system,Dam concrete construction,Guiding algorithm,Location based service,Warning algorithm},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\4HGHYXBZ\\Wu 等 - 2013 - A location based service approach for collision warning systems in concrete dam construction.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\MQXWLT8C\\S092575351200210X.html}
}

@article{XiaoZhiJunTaShiQiChongJiZhiNengLuJingGuiHuaYanJiuDTaiYuanKeJiDaXue2023,
  title = {肖智珺.塔式起重机智能路径规划研究[{{D}}].太原科技大学,2023.}
}

@article{xing-yuPositionposeMeasurementCrane2019,
  title = {Position-Pose Measurement of Crane Sway Based on Monocular Vision},
  author = {Xing-yu, Fu and Dan, Niu and Qi, Li and Jin-bo, Liu},
  date = {2019},
  journaltitle = {The Journal of Engineering},
  volume = {2019},
  number = {22},
  pages = {8330--8334},
  issn = {2051-3305},
  doi = {10.1049/joe.2019.1072},
  abstract = {The method of spatial positioning and pose measurement using computer vision have been widely used in satellite docking, motion control systems, navigation and guidance areas. A monocular vision measurement method of the telescope's spatial pose based on infrared target was proposed for the crane sway during industrial driving. An experimental system for monocular vision measurement of the crane spreader was established. Through the corresponding relationship between the geometric position of the infrared light spots and the imaging projection, the non-linear optimisation iterative method was used to solve the spatial pose parameters that were converted into four spreader model parameters. The system was measured under static conditions and dynamic pendulum for accuracy and real-time analysis. The experimental results show that the system can meet the real time and accuracy requirements of the spatial pose measurement of the crane sway.},
  langid = {english},
  keywords = {computer vision,computerised instrumentation,crane spreader,crane sway,cranes,geometric position,industrial driving,infrared imaging,infrared light spots,infrared target,iterative methods,mechanical engineering computing,monocular vision measurement method,nonlinear optimisation iterative method,nonlinear programming,pendulums,position measurement,position-pose measurement,spatial pose parameters,spatial positioning,spreader model parameters},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\WTI7Z4CJ\\Xing-yu 等 - 2019 - Position-pose measurement of crane sway based on monocular vision.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\H7UEJRS2\\joe.2019.html}
}

@article{xing-yuPositionposeMeasurementCrane2019a,
  title = {Position-Pose Measurement of Crane Sway Based on Monocular Vision},
  author = {Xing-yu, Fu and Dan, Niu and Qi, Li and Jin-bo, Liu},
  date = {2019},
  journaltitle = {The Journal of Engineering},
  volume = {2019},
  number = {22},
  pages = {8330--8334},
  issn = {2051-3305},
  doi = {10.1049/joe.2019.1072},
  abstract = {The method of spatial positioning and pose measurement using computer vision have been widely used in satellite docking, motion control systems, navigation and guidance areas. A monocular vision measurement method of the telescope's spatial pose based on infrared target was proposed for the crane sway during industrial driving. An experimental system for monocular vision measurement of the crane spreader was established. Through the corresponding relationship between the geometric position of the infrared light spots and the imaging projection, the non-linear optimisation iterative method was used to solve the spatial pose parameters that were converted into four spreader model parameters. The system was measured under static conditions and dynamic pendulum for accuracy and real-time analysis. The experimental results show that the system can meet the real time and accuracy requirements of the spatial pose measurement of the crane sway.},
  langid = {english},
  keywords = {computer vision,computerised instrumentation,crane spreader,crane sway,cranes,geometric position,industrial driving,infrared imaging,infrared light spots,infrared target,iterative methods,mechanical engineering computing,monocular vision measurement method,nonlinear optimisation iterative method,nonlinear programming,pendulums,position measurement,position-pose measurement,spatial pose parameters,spatial positioning,spreader model parameters},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\IMP78M2H\\Xing-yu 等 - 2019 - Position-pose measurement of crane sway based on monocular vision.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\FINY4FH8\\joe.2019.html}
}

@article{yangMinimumDistanceCalculation2024,
  title = {Minimum {{Distance Calculation Method}} for {{Collision Issues}} in {{Lifting Construction Scenarios}}},
  author = {Yang, Bin and Zhang, Haoran and Shen, Zhirong},
  date = {2024-11-01},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {38},
  number = {6},
  pages = {04024041},
  publisher = {American Society of Civil Engineers},
  doi = {10.1061/JCCEE5.CPENG-5914},
  abstract = {AbstractIn the construction process of prefabricated buildings, collision detection of the tower crane’s lifting path is of paramount importance. During the actual operation of a tower crane, attention is not only given to whether components collide with ...},
  langid = {english},
  keywords = {Collision detection,Lifting construction,Minimum distance calculation,Tower crane,Vertically aligned oriented bounding boxes (VA-OBB)}
}

@article{yangSafetyDistanceIdentification2019a,
  title = {Safety {{Distance Identification}} for {{Crane Drivers Based}} on {{Mask R-CNN}}},
  author = {Yang, Zhen and Yuan, Yongbo and Zhang, Mingyuan and Zhao, Xuefeng and Zhang, Yang and Tian, Boquan},
  date = {2019-01},
  journaltitle = {Sensors},
  volume = {19},
  number = {12},
  pages = {2789},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s19122789},
  abstract = {Tower cranes are the most commonly used large-scale equipment on construction site. Because workers can’t always pay attention to the environment at the top of the head, it is often difficult to avoid accidents when heavy objects fall. Therefore, safety construction accidents such as struck-by often occurs. In order to address crane issue, this research recorded video data by a tower crane camera, labeled the pictures, and operated image recognition with the MASK R-CNN method. Furthermore, The RGB color extraction was performed on the identified mask layer to obtain the pixel coordinates of workers and dangerous zone. At last, we used the pixel and actual distance conversion method to measure the safety distance. The contribution of this research to safety problem area is twofold: On one hand, without affecting the normal behavior of workers, an automatic collection, analysis, and early-warning system was established. On the other hand, the proposed automatic inspection system can help improve the safety operation of tower crane drivers.},
  langid = {english},
  keywords = {construction management,construction safety,cranes,imaging techniques,safety distance,安装在塔臂},
  file = {E:\tjustu\研究生\Zotero\storage\YFVMI4IM\Yang 等 - 2019 - Safety Distance Identification for Crane Drivers Based on Mask R-CNN.pdf}
}

@article{yangSafetyDistanceIdentification2019b,
  title = {Safety {{Distance Identification}} for {{Crane Drivers Based}} on {{Mask R-CNN}}},
  author = {Yang, Zhen and Yuan, Yongbo and Zhang, Mingyuan and Zhao, Xuefeng and Zhang, Yang and Tian, Boquan},
  date = {2019-01},
  journaltitle = {Sensors},
  volume = {19},
  number = {12},
  pages = {2789},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s19122789},
  abstract = {Tower cranes are the most commonly used large-scale equipment on construction site. Because workers can’t always pay attention to the environment at the top of the head, it is often difficult to avoid accidents when heavy objects fall. Therefore, safety construction accidents such as struck-by often occurs. In order to address crane issue, this research recorded video data by a tower crane camera, labeled the pictures, and operated image recognition with the MASK R-CNN method. Furthermore, The RGB color extraction was performed on the identified mask layer to obtain the pixel coordinates of workers and dangerous zone. At last, we used the pixel and actual distance conversion method to measure the safety distance. The contribution of this research to safety problem area is twofold: On one hand, without affecting the normal behavior of workers, an automatic collection, analysis, and early-warning system was established. On the other hand, the proposed automatic inspection system can help improve the safety operation of tower crane drivers.},
  langid = {english},
  keywords = {construction management,construction safety,cranes,imaging techniques,safety distance},
  file = {E:\tjustu\研究生\Zotero\storage\CHKI6RCS\Yang 等 - 2019 - Safety Distance Identification for Crane Drivers Based on Mask R-CNN.pdf}
}

@article{yongObjectDetectionDistance2023,
  title = {Object {{Detection}} and {{Distance Measurement Algorithm}} for {{Collision Avoidance}} of {{Precast Concrete Installation}} during {{Crane Lifting Process}}},
  author = {Yong, Yik Pong and Lee, Seo Joon and Chang, Young Hee and Lee, Kyu Hyup and Kwon, Soon Wook and Cho, Chung Suk and Chung, Su Wan},
  date = {2023-10},
  journaltitle = {Buildings},
  volume = {13},
  number = {10},
  pages = {2551},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2075-5309},
  doi = {10.3390/buildings13102551},
  abstract = {In the construction industry, the process of carrying heavy loads from one location to another by means of a crane is inevitable. This reliance on cranes to carry heavy loads is more obvious when it comes to high-rise building construction. Depending on the conditions and requirements on-site, various types of construction lifting equipment (i.e., cranes) are being used. As off-site construction (OSC) is gaining more traction recently, cranes are becoming more important throughout the construction project as precast concrete (PC) members are major components of OSC calling for lifting work. As a result of the increased use of cranes on construction sites, concerns about construction safety as well as the effectiveness of existing load collision prevention systems are attracting more attention from various parties involved. Besides the inherent risks associated with heavy load lifting, the unpredictable movement of on-site workers around the crane operation area, along with the presence of blind spots that obstruct the crane operator’s field-of-view (FOV), further increase the accident probability during crane operation. As such, the need for a more reliable and improved collision avoidance system that prevents lifted loads from hitting other structures and workers is paramount. This study introduces the application of deep learning-based object detection and distance measurement sensors integrated in a complementary way to achieve the stated need. Specifically, the object detection technique was used with the application of an Internet Protocol (IP) camera to detect the workers within the crane operation radius, whereas ultrasonic sensors were used to measure the distance of surrounding obstacles. Both applications were designed to work concurrently so as to prevent potential collisions during crane lifting operations. The field testing and evaluation of the integrated system showed promising results.},
  langid = {english},
  keywords = {collision avoidance,computer vision,crane,distance measurement sensor,object detection,off-site construction,precast concrete},
  file = {E:\tjustu\研究生\Zotero\storage\8QGSLR4A\Yong 等 - 2023 - Object Detection and Distance Measurement Algorithm for Collision Avoidance of Precast Concrete Inst.pdf}
}

@thesis{YuZhiMingTaDiaoAnQuanJianKongXiTongDeSheJiYuYanJiu2019,
  type = {硕士学位论文},
  title = {塔吊安全监控系统的设计与研究},
  author = {{郁志明}},
  namea = {{郝丽娜}},
  nameatype = {collaborator},
  date = {2019},
  journaltitle = {工程科技Ⅱ辑;信息科技},
  institution = {东北大学},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201901&filename=1019029559.nh},
  urldate = {2025-12-30},
  abstract = {近年来,随着建筑行业规模的不断扩大,塔吊机械设备在工地上的使用量越来越多。然而,由于塔吊干涉碰撞和塔吊违规超限作业等引起的安全事故频繁发生,造成生命财产的巨大损失。因此,必须从技术手段上加强对塔吊使用过程和行为进行及时有效的监督、切实预警以及安全控制,才能有效地防范和减少塔吊在运行过程中的危险因素和安全隐患。本论文中的塔吊安全监控系统是一种集电子技术、无线通信技术、自动控制、数据库管理等多种技术的综合性系统,能够高效率地完成塔吊运行工况的实时监控、单塔与塔群、障碍物作业干涉防碰撞、塔吊违规操作时声光报警并自动控制等。本文针对塔吊安全监控系统展开研究,主要内容如下:(1)硬件选型:塔吊安全监控系统硬件由幅度传感器、高度传感器、风速传感器、载重传感器、倾角传感器、无线通讯模块、视频模块、工业显示器、主控制器模块等模块组成。传感器模块主要用于监控塔吊上小车的位置参数、吊钩的高度参数、塔吊载重参数、塔吊力矩信息以及塔机运行环境风速信息等。ZigBee模块用于塔吊之间的塔吊工况参数数据的实时通信,通过自身塔机信息的检测以及与相关联塔机的信息交互,可实现塔机防碰撞、区域保护、超载保护、力矩保护、风速报警等功能。GPRS DTU模块主要功能是将设备数据实时传递给系统监控平台服务器,塔机安监部门、租赁部门等通过Internet网连接中心服务器,实现多方主体参与塔吊安全监控。主控制器的主要功能是将传感器传输的模拟信号转换为数字信号,并执行显示器下达的各种指令。工业显示器主要功能是实时显示塔吊各种工作状态数据,并发出声光报警提示等。(2)软件设计:系统在软件开发上,采用C\#开发程序语言,软件的功能模块主要包含了登录窗口和主窗体的设计、数据库和数据表单的设计、传感器数据读取、GPRS DTU网络连接、ZigBee无线传输以及报警功能等。各部分模块通过调试,能够实现将塔吊运行工况参数实时数据上传到塔吊监控平台,完成塔吊信息的实时监控的目的。(3)防碰撞设计:碰撞类型主要包括塔吊之间的相互碰撞、塔吊与障碍物之间的碰撞等。塔吊之间的碰撞按照塔吊自身的位置又划分3种可能,根据每种可能给出相应的判断条件、碰撞计算等。塔吊与障碍物之间的碰撞,主要是将障碍物划分为线性障碍物、圆柱形障碍物、长方体障碍物,比较实测的距离与安全距离的大小,以判断是否会有发生碰撞的可能性。},
  langid = {chinese},
  pagetotal = {101},
  keywords = {DTU模块,ZigBee模块,塔吊安全监控,远程监控,防碰撞设计},
  annotation = {major: 机械工程（专业学位）\\
download: 402\\
CLC: TU61;TP277\\
dbcode: CMFD\\
dbname: CMFD201901\\
filename: 1019029559.nh}
}

@article{zhangCranePoseEstimation2012,
  title = {Crane {{Pose Estimation Using UWB Real-Time Location System}}},
  author = {Zhang, C. and Hammad, A. and Rodriguez, S.},
  date = {2012-09-01},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {26},
  number = {5},
  pages = {625--637},
  publisher = {American Society of Civil Engineers},
  issn = {1943-5487},
  doi = {10.1061/(ASCE)CP.1943-5487.0000172},
  abstract = {AbstractOperating a crane is a complex job, which requires not only the experience of the operator, but also sufficient and appropriate real-time support to conceive and react to the environment. To help the crane operator, crane pose estimation is ...},
  langid = {english},
  keywords = {Construction equipment,Cranes,Estimation,Pose estimation,Real-time location system,Ultra wideband},
  file = {E:\tjustu\研究生\Zotero\storage\FFTVD86Q\Zhang 等 - 2012 - Crane Pose Estimation Using UWB Real-Time Location.pdf}
}

@article{ZhangDa2014Nian2022NianTaShiQiChongJiAnQuanShiGuAnLiTongJiFenXi2025,
  title = {2014年—2022年塔式起重机安全事故案例统计分析},
  author = {{张达}},
  date = {2025},
  journaltitle = {建筑安全},
  volume = {40},
  number = {2},
  pages = {81--85},
  issn = {1004-552X},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFQ&dbname=CJFDLAST2025&filename=JZAQ202502019},
  urldate = {2025-12-06},
  abstract = {近年来建筑塔式起重机安全事故多发，造成较大的人员和财产损失。基于此，对2014年—2022年的220例塔式起重机事故案例及事故调查报告展开统计分析，根据事故分布特征及发生原因，采取针对性预防措施，实现塔式起重机安全生产。塔式起重机安全生产是一个系统性工程，通过对事故发生的致因因素进行归类分析，指出事故预防的重点是对组织因素和人的因素进行干预，阻断事故发生的致因链，即应健全安全管理体系，加强现场安全管理，提升操作人员的安全意识和自觉按规章规程操作的意识和能力。},
  langid = {chinese},
  keywords = {事故等级,事故致因,事故预防,塔式起重机,安全事故},
  annotation = {original-container-title: Construction Safety\\
download: 316\\
CLC: X928\\
dbcode: CJFQ\\
dbname: CJFDLAST2025\\
filename: JZAQ202502019\\
publicationTag: JST\\
CIF: 0.391\\
AIF: 0.245}
}

@thesis{ZhangDongTaShiQiChongJiZhiNengJianKongXiTongYanJiuYuKaiFa2020,
  type = {硕士学位论文},
  title = {塔式起重机智能监控系统研究与开发},
  author = {{张冬}},
  namea = {{李彦明}},
  nameatype = {collaborator},
  date = {2020},
  journaltitle = {工程科技Ⅱ辑},
  institution = {上海交通大学},
  doi = {10.27307/d.cnki.gsjtu.2016.001713},
  abstract = {塔式起重机是工程机械领域中重要的运输工具,特别在高层房屋建设中具有重要的作用。由于塔式起重机的结构和使用特点致使其发生事故的频率较高且会造成严重的经济财产损失。研发一套监控塔式起重机工况安全的系统具有重要的价值和意义。在上述背景下,同时结合企业的监控需求,本文研发了一套基于ARM和ZIGBEE无线网络的塔式起重机智能监控系统,它能实时监控塔式起重机的工况信息数据并在人机交互系统上实时显示,同时监控碰撞危险,并及时发出报警信息。该系统还具备GSM远程通信和SD卡数据存储功能,以保障塔式起重机的操作运行安全。本文的主要工作如下:(1)分析了塔式起重机的结构和运行特点以及监控系统的功能需求,对塔式起重机工作系统进行数学建模,设计了监控系统的框架方案。(2)设计以ARM-STM32处理器为核心的硬件电路系统和嵌入式软件系统。硬件系统包括GPRS模块、AD模块、SD卡模块、报警模块和ZIGBEE无线通信模块;软件系统包括监控各功能模块的实现。(3)设计基于迪文科技串口屏的人机交互系统。通过该人机系统实现系统的初始化过程和塔式起重机必要工况信息的显示。(4)设计基于ZIGBEE的短距离无线通信网络和基于GSM的远程通信网络。塔式起重机之间通过ZIGBEE共享工况数据从而防止碰撞发生;通过GSM网络可以与远程监控平台通信,保证塔式起重机处于安全监控之下。(5)设计了塔式起重机防碰撞算法。在实时危险距离判断的基础上结合塔式起重机的运动速度信息,对防碰撞的时间进行预测,从而更高效的实现系统的防碰撞功能,提高塔式起重机的工作效率。本文最后对该监控系统进行了模拟实验同时对测试结果进行了分析。结论表明该监控系统能对塔式起重机群进行实时监控,对关键数据在线显示,对危险信息及时报警,有效防止塔式起重机防碰撞的发生,结果达到预期目标。},
  langid = {chinese},
  pagetotal = {112},
  keywords = {STM32,ZIGBEE,塔式起重机,防碰撞算法},
  annotation = {major: 机械电子工程\\
download: 209\\
CLC: TH213.3\\
dbcode: CMFD\\
dbname: CMFD202001\\
filename: 1019682799.nh}
}

@article{zhangImprovingLiftingMotion2012,
  title = {Improving Lifting Motion Planning and Re-Planning of Cranes with Consideration for Safety and Efficiency},
  author = {Zhang, Cheng and Hammad, Amin},
  date = {2012-04-01},
  journaltitle = {Advanced Engineering Informatics},
  shortjournal = {Advanced Engineering Informatics},
  series = {Knowledge Based Engineering to Support Complex Product Design},
  volume = {26},
  number = {2},
  pages = {396--410},
  issn = {1474-0346},
  doi = {10.1016/j.aei.2012.01.003},
  abstract = {Safe and efficient operation of cranes requires not only good planning, but also sufficient and appropriate support in real time. Due to the dynamic nature of construction sites, unexpected changes in site layout may create new obstacles for the crane that can result in collisions and accidents. Previous research on construction equipment motion planning focuses on off-line support, which considers static environment or predictable obstacles. These plans may not fit the reality when the environment has any change. In this case on-site safety and efficiency can be affected. In this research, a motion planning algorithm is proposed to efficiently generate safe and smooth paths for crane motions while taking into account engineering constraints and the path quality. Path smoothness is taken into account to provide a realistic path for cranes and to reduce unnecessary movements. A dynamic motion planning algorithm is proposed to ensure safety during the execution stage by quickly re-planning and avoiding collisions. In addition, an anytime algorithm is proposed to search for better solutions during a given time period by improving path smoothness and by reducing path execution time. The proposed algorithms are compared with other available algorithms to evaluate their performance in terms of planning and re-planning time and the cost of the path. Based on the literature review, this is the first time that dual-tree RRT algorithms have been applied to crane motion planning.},
  keywords = {Cranes,Motion planning,Re-planning,Safety and efficiency},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\AGYD8MN7\\Zhang和Hammad - 2012 - Improving lifting motion planning and re-planning of cranes with consideration for safety and effici.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\GMETEHMS\\S1474034612000043.html}
}

@article{zhangLiftPlanningOptimization2020,
  title = {Lift Planning and Optimization in Construction: {{A}} Thirty-Year Review},
  shorttitle = {Lift Planning and Optimization in Construction},
  author = {Zhang, Zhiqian and Pan, Wei},
  date = {2020-10-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {118},
  pages = {103271},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2020.103271},
  abstract = {Various lift planning and optimization (LPO) researches have been conducted; nevertheless, the body of knowledge is fragmented. This study aims to develop a systematic framework of LPO and predict its research trends, through a critical literature review, theoretical analysis, and model development. In total 108 journal papers from 1990 to 2019 are identified and analyzed based on the proposed taxonomy of LPO issues and methods. Results reveal an increasing trend of LPO for integrated issues using mixed methods. Owing to the evolving construction innovation like modular construction and thus the more challenging crane-lift problems, the use of innovative modeling methods (e.g. virtual reality simulation and intelligent algorithms) has increased. The complicated LPO issues should be integrated and addressed with appropriate modeling methods. The proposed framework contributes to systematic understanding on LPO and the suggested topics will drive future research to new heights in addressing the complexity and dynamics of LPO.},
  keywords = {Construction crane,Construction planning,Lift planning and optimization,Modular construction,Productivity},
  file = {E:\tjustu\研究生\Zotero\storage\TSDUWXPB\S0926580520302788.html}
}

@article{zhangMultiagentApproachRealTime2012a,
  title = {Multiagent {{Approach}} for {{Real-Time Collision Avoidance}} and {{Path Replanning}} for {{Cranes}}},
  author = {Zhang, Cheng and Hammad, Amin},
  date = {2012-11-01},
  journaltitle = {Journal of Computing in Civil Engineering},
  volume = {26},
  number = {6},
  pages = {782--794},
  publisher = {American Society of Civil Engineers},
  issn = {1943-5487},
  doi = {10.1061/(ASCE)CP.1943-5487.0000181},
  abstract = {AbstractCollisions on construction sites are one of the primary causes of fatal accidents. This paper proposes a multiagent-based approach to provide real-time support to the staff of construction projects. Collision avoidance is achieved by informing the ...},
  langid = {english},
  keywords = {Accidents,Collision avoidance,Construction equipment,Crane operations,Cranes,Multiagent,Path replanning,Safety},
  file = {E:\tjustu\研究生\Zotero\storage\SPXAWESQ\Zhang和Hammad - 2012 - Multiagent Approach for Real-Time Collision Avoidance and Path Replanning for Cranes.pdf}
}

@article{zhangOptimizationBasedCollisionAvoidance2021,
  title = {Optimization-{{Based Collision Avoidance}}},
  author = {Zhang, Xiaojing and Liniger, Alexander and Borrelli, Francesco},
  date = {2021-05},
  journaltitle = {IEEE Transactions on Control Systems Technology},
  volume = {29},
  number = {3},
  pages = {972--983},
  issn = {1558-0865},
  doi = {10.1109/TCST.2019.2949540},
  abstract = {This article presents a novel method for exactly reformulating nondifferentiable collision avoidance constraints into smooth, differentiable constraints using strong duality of convex optimization. We focus on a controlled object whose goal is to avoid obstacles while moving in an n-dimensional space. The proposed reformulation is exact, does not introduce any approximations, and applies to general obstacles and controlled objects that can be represented as the union of convex sets. We connect our results with the notion of signed distance, which is widely used in traditional trajectory generation algorithms. Our method can be applied to generic navigation and trajectory planning tasks, and the smoothness property allows the use of general-purpose gradient- and Hessian-based optimization algorithms. Finally, in case a collision cannot be avoided, our framework allows us to find “least-intrusive” trajectories, measured in terms of penetration. We demonstrate the efficacy of our framework on an automated parking problem, where our numerical experiments suggest that the proposed method is robust and enables real-time optimization-based trajectory planning in tight environments. Sample code of our example is provided at https://github.com/XiaojingGeorgeZhang/OBCA.},
  keywords = {Aerospace electronics,Autonomous driving,collision avoidance,Collision avoidance,model predictive control (MPC),Navigation,navigation in tight environments,nonlinear optimization,obstacle avoidance,Optimization,path planning,Planning,Robots,Trajectory,trajectory optimization},
  file = {E:\tjustu\研究生\Zotero\storage\UDXXY846\Zhang 等 - 2021 - Optimization-Based Collision Avoidance.pdf}
}

@article{zhangVisionTrajectoryBased2022,
  title = {Vision and {{Trajectory}}–{{Based Dynamic Collision Prewarning Mechanism}} for {{Tower Cranes}}},
  author = {Zhang, Mingyuan and Ge, Shoumeng},
  date = {2022-07-01},
  journaltitle = {Journal of Construction Engineering and Management},
  volume = {148},
  number = {7},
  pages = {04022057},
  publisher = {American Society of Civil Engineers},
  issn = {1943-7862},
  doi = {10.1061/(ASCE)CO.1943-7862.0002309},
  abstract = {AbstractTower cranes are very common at construction sites. As workers focus most of their attention on their own tasks, their ability to detect changes in the surrounding environment is reduced, and it is difficult to avoid the collision risk of heavy ...},
  langid = {english},
  keywords = {Collision avoidance,Computer vision,Multiple object tracking,Tower crane,Trajectory prediction},
  file = {E:\tjustu\研究生\Zotero\storage\G4N9T497\Zhang和Ge - 2022 - Vision and Trajectory–Based Dynamic Collision Prewarning Mechanism for Tower Cranes.pdf}
}

@article{ZhangWeiJiYuWuLianWangDeTaShiQiChongJiAnQuanJianKongXiTong2021,
  title = {基于物联网的塔式起重机安全监控系统},
  author = {{张伟} and {廖阳新} and {蒋灵} and {赵挺生}},
  date = {2021},
  journaltitle = {中国安全科学学报},
  volume = {31},
  number = {2},
  pages = {55--62},
  issn = {1003-3033},
  doi = {10.16265/j.cnki.issn1003-3033.2021.02.008},
  abstract = {为减少塔式起重机事故的发生概率,顺应信息化监测技术迅速发展的行业背景,提出一套基于物联网的塔式起重机安全监控系统。首先设计塔式起重机安全监控系统架构,结合其结构特点提出传感器布置方案。然后针对结构安全和安拆作业程序安全2个方面,以国家强制性标准为依据设置监测指标、预警阈值和预警等级;最后结合实际工程项目对监控系统方案进行现场试验。研究表明:塔式起重机结构安全监测应覆盖结构应力、垂直度、风速等指标;安拆作业程序监测应覆盖顶升高度、顶升速度、套架倾角等指标;结合物联网的数据采集、传输和处理功能,可实时监控塔式起重机的结构和作业状态。},
  langid = {chinese},
  keywords = {塔式起重机,安全监控系统,物联网,程序安全监测,结构安全监测},
  annotation = {original-container-title: China Safety Science Journal\\
foundation: 国家重点研发计划项目(2017YFC0805500)； 国家自然科学基金资助(51308240)；\\
download: 1221\\
CLC: TH213.3;TP277\\
dbcode: CJFQ\\
dbname: CJFDLAST2021\\
filename: ZAQK202102008\\
publicationTag: 北大核心, CAS, JST, EI, CSCD, WJCI, 卓越期刊\\
CIF: 3.085\\
AIF: 2.178},
  file = {E:\tjustu\研究生\Zotero\storage\PRQ9T6LH\张伟 等 - 2021 - 基于物联网的塔式起重机安全监控系统.pdf}
}

@article{ZhangZhiTianTaDiaoYuGongRenKongJianJiaoHuXiaWeiXianChangJingZiDongJianCe2024,
  title = {塔吊与工人空间交互下危险场景自动检测},
  author = {{张知田} and {王园园} and {罗柱邦} and {郭子扬} and {郭红领}},
  date = {2024},
  journaltitle = {清华大学学报（自然科学版）},
  volume = {64},
  number = {2},
  pages = {198--204},
  issn = {1000-0054},
  doi = {10.16511/j.cnki.qhdxxb.2023.22.047},
  abstract = {塔吊作业具有持续时间长、范围大以及与工人空间交互复杂的特点，导致塔吊事故频发且往往损失重大。为了提升塔吊运行相关危险场景检测的及时性和有效性，该文基于信息化手段，提出了塔吊运行过程中危险场景的自动检测方法。该方法基于建筑信息模型(BIM)、传感器和计算机视觉等技术，通过获取塔吊运行状态与工人作业状态，分析两者之间的空间交互关系，在判别规则的基础上实现了危险场景自动检测。案例应用表明，该自动检测方法是可行的和有效的。},
  langid = {chinese},
  keywords = {危险场景,塔吊,工人,施工安全,自动检测},
  annotation = {original-container-title: Journal of Tsinghua University(Science and Technology)\\
foundation: 国家自然科学基金面上项目(52278310)； 清华大学“水木学者”计划；\\
download: 518\\
CLC: TP391.41;TU714\\
dbcode: CJFQ\\
dbname: CJFDLAST2024\\
filename: QHXB202402004\\
publicationTag: 北大核心, CAS, INSPEC, JST, EI, CSCD, WJCI, 卓越期刊\\
CIF: 3.56\\
AIF: 1.913},
  file = {E:\tjustu\研究生\Zotero\storage\PQKUALGJ\张知田 等 - 2024 - 塔吊与工人空间交互下危险场景自动检测.pdf}
}

@thesis{ZhaoYuTaDiaoQunZuoYeWuXianZuWangJiShuYuFangPengZhuangSuanFaYanJiu2017,
  type = {硕士学位论文},
  title = {塔吊群作业无线组网技术与防碰撞算法研究},
  author = {{赵宇}},
  namea = {{许景波}},
  nameatype = {collaborator},
  date = {2017},
  journaltitle = {工程科技Ⅱ辑},
  institution = {哈尔滨理工大学},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201701&filename=1016072789.nh},
  urldate = {2025-12-30},
  abstract = {塔式起重机是建筑行业必不可少的重要运输设备。随着建筑工程项目的不断增加、建设施工也要求效率越来越高,在同一施工区域内塔机的布置会越来越密集,容易发生塔吊的碰撞事故。目前针对塔吊事故研究了多种防碰撞方法,大多数是对本塔吊自身的的保护。对于群塔机作业的碰撞问题上需要有更全面的研究。在避免发生碰撞的基础上,还要提高工作效率。本文以ZigBee无线通信技术为网络通信基础,结合超声波测距技术研究出了一套针对塔吊群作业的智能防碰撞系统。本设计由塔吊主控室内的中央处理器采集塔吊的工作参数,并设计了一种宽范围的超声波探测器安装在塔机的吊臂上,用来检测塔吊臂与障碍物的距离。在群塔作业的区域内,采用ZigBee无线通信技术将多个塔机组成独特的网络拓扑结构,完成塔机之间信息的交换。最后采用层次包围球与齐次坐标变换这两种算法相结合的方式,对塔吊群作业的进行防碰撞的运算,之后采用Matlab VR软件实现防碰撞系统的仿真。有效的减少了塔吊群工作时可能发生的碰撞事故。塔吊群作业的防碰撞系统采用了超声波探测与防碰撞算法相结合的方式有效减少了群塔作业时塔吊的事故发生率。通过对塔吊位置信息的采集,基于无线通信技术完成了塔吊之间信息的交换,为防碰撞的运算提供了数据基础。整个系统安全可靠,算法计算效率高,提供了群塔作业时的安全保障,具有一定的实用推广价值。},
  langid = {chinese},
  pagetotal = {60},
  keywords = {ZigBee组网,塔吊群,超声波,防碰撞算法},
  annotation = {major: 仪器科学与技术\\
download: 242\\
CLC: TU61\\
dbcode: CMFD\\
dbname: CMFD201701\\
filename: 1016072789.nh}
}

@article{zhongCameraRadarFusion2018,
  title = {Camera {{Radar Fusion}} for {{Increased Reliability}} in {{ADAS Applications}}},
  author = {Zhong, Ziguo and Liu, Stanley and Mathew, Manu and Dubey, Aish and Liu, Stanley and Mathew, Manu and Dubey, Aish},
  date = {2018-01-28},
  journaltitle = {Electronic Imaging},
  volume = {30},
  pages = {1--4},
  publisher = {{Society for Imaging Science and Technology}},
  issn = {2470-1173},
  doi = {10.2352/ISSN.2470-1173.2018.17.AVM-258},
  abstract = {Driven by the mandated adoption of advanced safety features enforced by governments around the global as well as strong demands for upgraded safety and convenience experience from the consumer side, the automotive industry is going through an intensified arms race of equipping vehicles with more sensors and boosted computation capacity. Among various sensors, camera and radar stand out as a popular combination offering complementary capabilities. As a result, camera radar fusion (or CRF in short) has been regarded as one of the key technology trends for future advanced driving assistant system (ADAS). This paper reports a camera radar fusion system developed at TI, which is powered by a broad set of TI silicon products, including CMOS radar, TDA SoC processor, FPD-Link II/III SerDes, PMIC, and so forth. The system is developed to not only showcase algorithmic benefits of fusion, but also the competitiveness of TI solutions as a whole in terms of coverage of capabilities, balance between performance and energy efficiency, and rich supports from the associated HW and SW ecosystem.},
  langid = {english},
  file = {E:\tjustu\研究生\Zotero\storage\8G9VR9K4\Zhong 等 - 2018 - Camera Radar Fusion for Increased Reliability in ADAS Applications.pdf}
}

@book{ZhongHuaRenMinGongHeGuoGuoJiaTongJiJu2023ZhongGuoTongJiNianJianM,
  title = {中华人民共和国国家统计局. 2023 中国统计年鉴[{{M}}]. 北京：中国统计出版，2023.}
}

@article{zhongPracticalApplicationCombining2014,
  title = {A {{Practical Application Combining Wireless Sensor Networks}} and {{Internet}} of {{Things}}: {{Safety Management System}} for {{Tower Crane Groups}}},
  shorttitle = {A {{Practical Application Combining Wireless Sensor Networks}} and {{Internet}} of {{Things}}},
  author = {Zhong, Dexing and Lv, Hongqiang and Han, Jiuqiang and Wei, Quanrui},
  date = {2014-07-30},
  journaltitle = {Sensors (Basel, Switzerland)},
  shortjournal = {Sensors (Basel)},
  volume = {14},
  number = {8},
  eprint = {25196106},
  eprinttype = {pubmed},
  pages = {13794--13814},
  issn = {1424-8220},
  doi = {10.3390/s140813794},
  abstract = {The so-called Internet of Things (IoT) has attracted increasing attention in the field of computer and information science. In this paper, a specific application of IoT, named Safety Management System for Tower Crane Groups (SMS-TC), is proposed for use in the construction industry field. The operating status of each tower crane was detected by a set of customized sensors, including horizontal and vertical position sensors for the trolley, angle sensors for the jib and load, tilt and wind speed sensors for the tower body. The sensor data is collected and processed by the Tower Crane Safety Terminal Equipment (TC-STE) installed in the driver's operating room. Wireless communication between each TC-STE and the Local Monitoring Terminal (LMT) at the ground worksite were fulfilled through a Zigbee wireless network. LMT can share the status information of the whole group with each TC-STE, while the LMT records the real-time data and reports it to the Remote Supervision Platform (RSP) through General Packet Radio Service (GPRS). Based on the global status data of the whole group, an anti-collision algorithm was executed in each TC-STE to ensure the safety of each tower crane during construction. Remote supervision can be fulfilled using our client software installed on a personal computer (PC) or smartphone. SMS-TC could be considered as a promising practical application that combines a Wireless Sensor Network with the Internet of Things.},
  pmcid = {PMC4179015},
  file = {E:\tjustu\研究生\Zotero\storage\QLIALQ2G\Zhong 等 - 2014 - A Practical Application Combining Wireless Sensor Networks and Internet of Things Safety Management.pdf}
}

@thesis{ZhouFeiHuTaShiQiChongJiFangPengZhuangJiShuYuAnQuanJianKongXiTongYanJiu2016,
  type = {硕士学位论文},
  title = {塔式起重机防碰撞技术与安全监控系统研究},
  author = {{周飞虎}},
  namea = {{高子渝}},
  nameatype = {collaborator},
  date = {2016},
  journaltitle = {工程科技Ⅱ辑},
  institution = {长安大学},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201601&filename=1015802742.nh},
  urldate = {2025-12-30},
  abstract = {塔式起重机作为一种重要的起重运输机械,在建筑施工中发挥着关键作用。目前,国内塔机的安全保护装置对预防碰撞的作用有限,时有事故发生,对社会造成了重大影响。因此,对塔机防碰撞安全监控系统的研究,对建筑施工安全有重要意义。本论文对塔式起重机的多参数监控和多机防碰撞技术进行了研究。针对现有的风险预估算法和实时动态位置计算的防碰撞算法的不足,基于塔机间通讯数据量小、算法简单的要求,提出了通过全程跟踪监控,利用向量计算塔机间距离的防碰撞算法,相较于经典方法比较简单、易于实现。根据塔机的动作差别和运动方向、速度的不同,在不同的碰撞工况下,给出了不同的报警距离计算方法,作为判断塔机是否会发生碰撞的标准,避免了一些特殊的危险工况,同时提高了工作效率与可靠性,采用MATLAB,对塔机的5种碰撞工况进行仿真,验证了算法的可行性。采用西门子S7-200 224XP CPU完成了系统的硬件设计,通过SMART 700 IE触摸屏显示塔机工作状态信息,采用Zigbee数传模块进行塔机之间防碰撞参数的传输,确定了监测塔机参数传感器的安装位置、标定方法和报警设置。基于STEP 7-Micro/WIN的环境,对系统的主程序、信号采集、无线通信和防碰撞程序进行了开发。基于WinCC flexible组态软件,设计了触摸屏的主监控界面、传感器标定界面、多机防碰撞设置界面等操作界面。通过在实验室的模拟试验,验证系统的可行性与有效性。},
  langid = {chinese},
  pagetotal = {65},
  keywords = {PLC,Zigbee,塔式起重机,安全监控,防碰撞},
  annotation = {major: 机械电子工程\\
download: 446\\
CLC: TH213.3\\
dbcode: CMFD\\
dbname: CMFD201601\\
filename: 1015802742.nh},
  file = {E:\tjustu\研究生\Zotero\storage\P6XWPTA6\周飞虎 - 2016 - 塔式起重机防碰撞技术与安全监控系统研究.pdf}
}

@article{zhouPixelLevelFusionInfrared2009,
  title = {Pixel-{{Level Fusion}} for {{Infrared}} and {{Visible Acquisitions}}},
  author = {Zhou, Yi and Omar, Mohammed},
  date = {2009-02-25},
  journaltitle = {International Journal of Optomechatronics},
  volume = {3},
  number = {1},
  pages = {41--53},
  publisher = {Taylor \& Francis},
  issn = {1559-9612},
  doi = {10.1080/15599610902717835},
  abstract = {This article presents a unique combined routine to fuse Long Wave Infrared (7.5–13~micron) with visible (0.38–0.78~micron) acquisitions, and to track pedestrians and road information in night or low light driving scenarios. Three fusion levels are presented and discussed: pixel-level, feature-level and decision-level. A pixel-level fusion is then used, through a novel combination of an adaptive weighting algorithm for un-saturated data points, and a PCA statistics for saturated pixels. The registration is done at the hardware level with Gaussian smoothing, while the smoothed histograms provide initial threshold values. The proposed routine is then applied for different night-time driving scenarios, further compared with the tracking results for non-fused thermal imagery from a commercial night-vision module. The fused imagery coupled with the proposed pre and post-processing provide complete detection of reflective and emitting objects with better shape retrieval and orientation prediction, computed and judged through objects morphology. The result of current work is an enhanced passive display for: passing vehicles with glare, pedestrians and non-emitting road features, with its motion predicted.},
  keywords = {average thresholding,image fusion,night vision,pixel-level fusion,vehicle tracking},
  file = {E:\tjustu\研究生\Zotero\storage\45IQNTML\Zhou和Omar - 2009 - Pixel-Level Fusion for Infrared and Visible Acquisitions.pdf}
}

@article{zhuCraneliftPathPlanning2022,
  title = {Crane-Lift Path Planning for High-Rise Modular Integrated Construction through Metaheuristic Optimization and Virtual Prototyping},
  author = {Zhu, Aimin and Zhang, Zhiqian and Pan, Wei},
  date = {2022-09-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {141},
  pages = {104434},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2022.104434},
  abstract = {Heavy crane lifting in high-rise modular integrated construction (MiC) is critical but challenging. The current crane-lift executions are heavily reliant on human judgment. Few studies on crane-lift path planning considered modular-specific characteristics such as installation of hefty modules. Therefore, this study aims to develop an automatic crane-lift path planning system to achieve safe and efficient module installation in high-rise MiC. The system involves an innovative metaheuristic algorithm for path optimization and a virtual prototyping-based platform for crane-lift simulation, and was validated using a real-life MiC project. The results reveal that the proposed algorithm that combines particle swarm optimization and simulated annealing is efficient in deriving a collision-free path, and outperforms other metaheuristics. The platform was demonstrated to be effective and informative in simulating various crane lifts. This study should facilitate safe and efficient delivery of high-rise modular buildings by contributing an intelligent algorithm and a virtual simulation platform.},
  keywords = {Heavy crane-lift path planning,Modular integrated construction,Particle swarm optimization,Path simulation,Simulated annealing},
  file = {E:\tjustu\研究生\Zotero\storage\5UBIFYHD\S0926580522003077.html}
}

@article{zhuDevelopingFastAccurate2024,
  title = {Developing a Fast and Accurate Collision Detection Strategy for Crane-Lift Path Planning in High-Rise Modular Integrated Construction},
  author = {Zhu, Aimin and Zhang, Zhiqian and Pan, Wei},
  date = {2024-08-01},
  journaltitle = {Advanced Engineering Informatics},
  shortjournal = {Advanced Engineering Informatics},
  volume = {61},
  pages = {102509},
  issn = {1474-0346},
  doi = {10.1016/j.aei.2024.102509},
  abstract = {Crane-lift path planning (CLPP) ensures the safe and efficient installation of hefty modules in high-rise modular integrated construction (MiC). The implementation of CLPP requires effective collision detection strategies. However, existing collision detection strategies suffer from limitations in terms of computational intensity or insufficient accuracy. This paper aims to develop a fast and accurate collision detection strategy for CLPP in high-rise MiC projects using a single tower crane, thereby achieving safe and efficient module installation. It is executed with the assumptions that the geometry of the building remains unchanged, the positions and orientations of the lifted module and the tower crane are monitored, and no external loads act on the lifted module. Based on the research scope and assumptions, an octree and bounding box (Oct-Box) integrated strategy is developed. The strategy operates in two stages, the pre-execution and execution stages, supported by two critical technical components: (1) an optimized octree for lifting space division and encoding, and (2) an integrated bounding box algorithm for construction object collision detection. The strategy was evaluated using a real-life MiC project in Hong Kong. The results show that the developed strategy minimized the CLPP time by about 95\,\%, while ensuring continuous and accurate collision detection. In addition, the strategy was significantly affected by the depth of octree, the encoding method of octree, the bounding box algorithm and the configuration density. The developed Oct-Box strategy for CLPP is novel as it addresses temporal efficiency and spatial tightness in tandem, and marks a breakthrough for collision detection in modular construction.},
  keywords = {Collision detection,Crane-lift,Modular integrated construction,Path planning},
  file = {E\:\\tjustu\\研究生\\Zotero\\storage\\DU8KAB8Q\\Zhu 等 - 2024 - Developing a fast and accurate collision detection strategy for crane-lift path planning in high-ris.pdf;E\:\\tjustu\\研究生\\Zotero\\storage\\WPJ6UGXL\\S1474034624001575.html}
}
